{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36a766c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "\n",
    "spacy.require_gpu()\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95749cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2492f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_directory = '../processed_data/'\n",
    "train_df = pd.read_json('../processed_data/train.json')\n",
    "test_df = pd.read_json('../processed_data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3f6a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>4932</td>\n",
       "      <td>In Panic In The Streets Richard Widmark plays ...</td>\n",
       "      <td>8</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24016</th>\n",
       "      <td>9115</td>\n",
       "      <td>If you ask me the first one was really better ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9668</th>\n",
       "      <td>7452</td>\n",
       "      <td>I am a big fan a Faerie Tale Theatre and I've ...</td>\n",
       "      <td>10</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>11026</td>\n",
       "      <td>I just finished reading a book about Dillinger...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14018</th>\n",
       "      <td>11367</td>\n",
       "      <td>Greg Davis and Bryan Daly take some crazed sta...</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21575</th>\n",
       "      <td>6919</td>\n",
       "      <td>My roommates &amp; I nearly shorted out our TV fro...</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>3601</td>\n",
       "      <td>Michelle Rodriguez is the defining actress who...</td>\n",
       "      <td>7</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>10775</td>\n",
       "      <td>Nice movie with a great soundtrack which spans...</td>\n",
       "      <td>8</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1716</td>\n",
       "      <td>Even though this was a made-for-TV production,...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23654</th>\n",
       "      <td>8790</td>\n",
       "      <td>I saw this on cable recently and kinda enjoyed...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  rating label\n",
       "6868    4932  In Panic In The Streets Richard Widmark plays ...       8     +\n",
       "24016   9115  If you ask me the first one was really better ...       1     -\n",
       "9668    7452  I am a big fan a Faerie Tale Theatre and I've ...      10     +\n",
       "13640  11026  I just finished reading a book about Dillinger...       1     -\n",
       "14018  11367  Greg Davis and Bryan Daly take some crazed sta...       2     -\n",
       "...      ...                                                ...     ...   ...\n",
       "21575   6919  My roommates & I nearly shorted out our TV fro...       2     -\n",
       "5390    3601  Michelle Rodriguez is the defining actress who...       7     +\n",
       "860    10775  Nice movie with a great soundtrack which spans...       8     +\n",
       "15795   1716  Even though this was a made-for-TV production,...       1     -\n",
       "23654   8790  I saw this on cable recently and kinda enjoyed...       1     -\n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sample(len(train_df), random_state=42)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df72f025",
   "metadata": {},
   "source": [
    "# Storing some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7edcbbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(0.8*len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6eff201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2092b3c2ee0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2092b3c2c40>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2092b09fc80>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2092b5e7800>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2092b603a40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2092b09fc10>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e76b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(row):\n",
    "    if row == '-':\n",
    "        return [1, 0]\n",
    "    else:\n",
    "        return [0, 1]\n",
    "    \n",
    "def get_features(df):\n",
    "    text_list = df['text'].to_list()\n",
    "    x = []\n",
    "    for doc in tqdm_notebook(nlp.pipe(text_list, disable=[\"tagger\", \"parser\", \"lemmatizer\", 'attribute_ruler', 'ner']),total=len(text_list) ):\n",
    "        x.append(doc.vector.get())\n",
    "    x = pd.DataFrame(x)\n",
    "    y = df['label'].apply(one_hot).tolist()\n",
    "    y = np.array(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b73ed6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9f16c280d3475f99dc8d9fec931a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_x, train_y \u001b[38;5;241m=\u001b[39m \u001b[43mget_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test_x, test_y \u001b[38;5;241m=\u001b[39m get_features(test_df)\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mget_features\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     12\u001b[0m x \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(x)\n\u001b[0;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(one_hot)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 14\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray(y)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "train_x, train_y = get_features(train_df)\n",
    "test_x, test_y = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9e92a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.152942</td>\n",
       "      <td>-0.131309</td>\n",
       "      <td>-0.036154</td>\n",
       "      <td>0.122642</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>-0.016544</td>\n",
       "      <td>-0.126087</td>\n",
       "      <td>-0.029805</td>\n",
       "      <td>2.124057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164012</td>\n",
       "      <td>0.049071</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>-0.056707</td>\n",
       "      <td>0.007302</td>\n",
       "      <td>-0.010890</td>\n",
       "      <td>-0.064989</td>\n",
       "      <td>-0.071053</td>\n",
       "      <td>-0.014184</td>\n",
       "      <td>0.045542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.130510</td>\n",
       "      <td>-0.104212</td>\n",
       "      <td>-0.063575</td>\n",
       "      <td>0.084911</td>\n",
       "      <td>-0.025344</td>\n",
       "      <td>-0.035447</td>\n",
       "      <td>-0.114975</td>\n",
       "      <td>-0.006386</td>\n",
       "      <td>1.935403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190982</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>-0.029648</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.024023</td>\n",
       "      <td>-0.044958</td>\n",
       "      <td>-0.012830</td>\n",
       "      <td>0.056736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.097324</td>\n",
       "      <td>0.184632</td>\n",
       "      <td>-0.128490</td>\n",
       "      <td>-0.084664</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>0.032274</td>\n",
       "      <td>0.047223</td>\n",
       "      <td>-0.114767</td>\n",
       "      <td>0.014312</td>\n",
       "      <td>2.152641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.172063</td>\n",
       "      <td>0.022724</td>\n",
       "      <td>-0.101178</td>\n",
       "      <td>-0.023656</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.068299</td>\n",
       "      <td>-0.024370</td>\n",
       "      <td>-0.091496</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>0.093178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.027772</td>\n",
       "      <td>0.130567</td>\n",
       "      <td>-0.152985</td>\n",
       "      <td>-0.047217</td>\n",
       "      <td>0.071326</td>\n",
       "      <td>0.016790</td>\n",
       "      <td>-0.003706</td>\n",
       "      <td>-0.101126</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>2.152511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233026</td>\n",
       "      <td>0.042364</td>\n",
       "      <td>-0.024650</td>\n",
       "      <td>-0.034881</td>\n",
       "      <td>0.024407</td>\n",
       "      <td>0.030208</td>\n",
       "      <td>-0.044393</td>\n",
       "      <td>-0.083346</td>\n",
       "      <td>0.033778</td>\n",
       "      <td>0.086929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.027660</td>\n",
       "      <td>0.171387</td>\n",
       "      <td>-0.097587</td>\n",
       "      <td>-0.055611</td>\n",
       "      <td>0.107496</td>\n",
       "      <td>0.039108</td>\n",
       "      <td>0.027723</td>\n",
       "      <td>-0.104099</td>\n",
       "      <td>-0.018723</td>\n",
       "      <td>2.075550</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155245</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>-0.011114</td>\n",
       "      <td>-0.040261</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.027404</td>\n",
       "      <td>-0.046025</td>\n",
       "      <td>-0.048126</td>\n",
       "      <td>-0.025229</td>\n",
       "      <td>0.035457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>-0.030652</td>\n",
       "      <td>0.130034</td>\n",
       "      <td>-0.115811</td>\n",
       "      <td>-0.049625</td>\n",
       "      <td>0.089282</td>\n",
       "      <td>-0.006514</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>-0.112348</td>\n",
       "      <td>-0.015421</td>\n",
       "      <td>2.150479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164964</td>\n",
       "      <td>0.049693</td>\n",
       "      <td>0.025036</td>\n",
       "      <td>-0.068340</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.045247</td>\n",
       "      <td>-0.028728</td>\n",
       "      <td>0.007879</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>0.092720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>-0.030462</td>\n",
       "      <td>0.185232</td>\n",
       "      <td>-0.091917</td>\n",
       "      <td>-0.073782</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>0.055192</td>\n",
       "      <td>0.038778</td>\n",
       "      <td>-0.165647</td>\n",
       "      <td>-0.020743</td>\n",
       "      <td>2.113348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188884</td>\n",
       "      <td>0.054723</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>-0.019912</td>\n",
       "      <td>0.050026</td>\n",
       "      <td>-0.051562</td>\n",
       "      <td>-0.068628</td>\n",
       "      <td>-0.098007</td>\n",
       "      <td>-0.023132</td>\n",
       "      <td>0.143531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>-0.006854</td>\n",
       "      <td>0.121101</td>\n",
       "      <td>-0.092479</td>\n",
       "      <td>-0.042141</td>\n",
       "      <td>0.070015</td>\n",
       "      <td>-0.053947</td>\n",
       "      <td>0.029291</td>\n",
       "      <td>-0.094470</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>1.957572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149024</td>\n",
       "      <td>0.020803</td>\n",
       "      <td>0.017507</td>\n",
       "      <td>-0.023384</td>\n",
       "      <td>-0.011275</td>\n",
       "      <td>0.019338</td>\n",
       "      <td>-0.048050</td>\n",
       "      <td>-0.083139</td>\n",
       "      <td>-0.070448</td>\n",
       "      <td>0.045597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.011233</td>\n",
       "      <td>0.128624</td>\n",
       "      <td>-0.120690</td>\n",
       "      <td>-0.084393</td>\n",
       "      <td>0.079866</td>\n",
       "      <td>0.054415</td>\n",
       "      <td>0.022280</td>\n",
       "      <td>-0.146740</td>\n",
       "      <td>0.024745</td>\n",
       "      <td>2.133624</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178119</td>\n",
       "      <td>0.093841</td>\n",
       "      <td>-0.012928</td>\n",
       "      <td>-0.043249</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>-0.012723</td>\n",
       "      <td>-0.033844</td>\n",
       "      <td>-0.008538</td>\n",
       "      <td>0.097597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>-0.033906</td>\n",
       "      <td>0.118301</td>\n",
       "      <td>-0.111804</td>\n",
       "      <td>-0.031310</td>\n",
       "      <td>0.080290</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>-0.028345</td>\n",
       "      <td>-0.160925</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>2.289585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201878</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>0.023464</td>\n",
       "      <td>-0.060458</td>\n",
       "      <td>0.018191</td>\n",
       "      <td>0.053610</td>\n",
       "      <td>-0.047162</td>\n",
       "      <td>-0.025714</td>\n",
       "      <td>-0.016015</td>\n",
       "      <td>0.119650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.006977  0.152942 -0.131309 -0.036154  0.122642  0.012373 -0.016544   \n",
       "1      0.012072  0.130510 -0.104212 -0.063575  0.084911 -0.025344 -0.035447   \n",
       "2     -0.097324  0.184632 -0.128490 -0.084664  0.054203  0.032274  0.047223   \n",
       "3     -0.027772  0.130567 -0.152985 -0.047217  0.071326  0.016790 -0.003706   \n",
       "4     -0.027660  0.171387 -0.097587 -0.055611  0.107496  0.039108  0.027723   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995 -0.030652  0.130034 -0.115811 -0.049625  0.089282 -0.006514  0.038002   \n",
       "24996 -0.030462  0.185232 -0.091917 -0.073782  0.093834  0.055192  0.038778   \n",
       "24997 -0.006854  0.121101 -0.092479 -0.042141  0.070015 -0.053947  0.029291   \n",
       "24998  0.011233  0.128624 -0.120690 -0.084393  0.079866  0.054415  0.022280   \n",
       "24999 -0.033906  0.118301 -0.111804 -0.031310  0.080290  0.008416 -0.028345   \n",
       "\n",
       "              7         8         9  ...       290       291       292  \\\n",
       "0     -0.126087 -0.029805  2.124057  ... -0.164012  0.049071  0.032471   \n",
       "1     -0.114975 -0.006386  1.935403  ... -0.190982  0.006450  0.008672   \n",
       "2     -0.114767  0.014312  2.152641  ... -0.172063  0.022724 -0.101178   \n",
       "3     -0.101126 -0.009193  2.152511  ... -0.233026  0.042364 -0.024650   \n",
       "4     -0.104099 -0.018723  2.075550  ... -0.155245  0.034445 -0.011114   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "24995 -0.112348 -0.015421  2.150479  ... -0.164964  0.049693  0.025036   \n",
       "24996 -0.165647 -0.020743  2.113348  ... -0.188884  0.054723  0.005237   \n",
       "24997 -0.094470  0.001424  1.957572  ... -0.149024  0.020803  0.017507   \n",
       "24998 -0.146740  0.024745  2.133624  ... -0.178119  0.093841 -0.012928   \n",
       "24999 -0.160925  0.004423  2.289585  ... -0.201878  0.036660  0.023464   \n",
       "\n",
       "            293       294       295       296       297       298       299  \n",
       "0     -0.056707  0.007302 -0.010890 -0.064989 -0.071053 -0.014184  0.045542  \n",
       "1     -0.029648  0.027210  0.010179  0.024023 -0.044958 -0.012830  0.056736  \n",
       "2     -0.023656  0.044661  0.068299 -0.024370 -0.091496 -0.002683  0.093178  \n",
       "3     -0.034881  0.024407  0.030208 -0.044393 -0.083346  0.033778  0.086929  \n",
       "4     -0.040261  0.006755  0.027404 -0.046025 -0.048126 -0.025229  0.035457  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "24995 -0.068340  0.005200  0.045247 -0.028728  0.007879  0.023769  0.092720  \n",
       "24996 -0.019912  0.050026 -0.051562 -0.068628 -0.098007 -0.023132  0.143531  \n",
       "24997 -0.023384 -0.011275  0.019338 -0.048050 -0.083139 -0.070448  0.045597  \n",
       "24998 -0.043249  0.075504 -0.001530 -0.012723 -0.033844 -0.008538  0.097597  \n",
       "24999 -0.060458  0.018191  0.053610 -0.047162 -0.025714 -0.016015  0.119650  \n",
       "\n",
       "[25000 rows x 300 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d0f64ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       +  -\n",
       "0      1  0\n",
       "1      1  0\n",
       "2      0  1\n",
       "3      1  0\n",
       "4      1  0\n",
       "...   .. ..\n",
       "24995  0  1\n",
       "24996  1  0\n",
       "24997  1  0\n",
       "24998  1  0\n",
       "24999  0  1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bfeec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, input_shape=(300,), activation='relu'),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "callbacks=[\n",
    "    ModelCheckpoint(filepath='./models_ffnn/checkpoint',\n",
    "                   save_best_only=True, verbose=1,monitor='val_accuracy')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4143131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "541/547 [============================>.] - ETA: 0s - loss: 0.4430 - accuracy: 0.7914\n",
      "Epoch 1: val_accuracy improved from -inf to 0.83173, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "547/547 [==============================] - 4s 6ms/step - loss: 0.4430 - accuracy: 0.7917 - val_loss: 0.4070 - val_accuracy: 0.8317\n",
      "Epoch 2/50\n",
      "544/547 [============================>.] - ETA: 0s - loss: 0.3852 - accuracy: 0.8320\n",
      "Epoch 2: val_accuracy improved from 0.83173 to 0.85173, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "547/547 [==============================] - 3s 6ms/step - loss: 0.3850 - accuracy: 0.8320 - val_loss: 0.3523 - val_accuracy: 0.8517\n",
      "Epoch 3/50\n",
      "533/547 [============================>.] - ETA: 0s - loss: 0.3714 - accuracy: 0.8398\n",
      "Epoch 3: val_accuracy improved from 0.85173 to 0.85187, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "547/547 [==============================] - 3s 6ms/step - loss: 0.3721 - accuracy: 0.8392 - val_loss: 0.3542 - val_accuracy: 0.8519\n",
      "Epoch 4/50\n",
      "547/547 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8417\n",
      "Epoch 4: val_accuracy improved from 0.85187 to 0.86453, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "547/547 [==============================] - 3s 6ms/step - loss: 0.3627 - accuracy: 0.8417 - val_loss: 0.3338 - val_accuracy: 0.8645\n",
      "Epoch 5/50\n",
      "538/547 [============================>.] - ETA: 0s - loss: 0.3566 - accuracy: 0.8459\n",
      "Epoch 5: val_accuracy did not improve from 0.86453\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3569 - accuracy: 0.8453 - val_loss: 0.3551 - val_accuracy: 0.8617\n",
      "Epoch 6/50\n",
      "544/547 [============================>.] - ETA: 0s - loss: 0.3491 - accuracy: 0.8498\n",
      "Epoch 6: val_accuracy did not improve from 0.86453\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3497 - accuracy: 0.8497 - val_loss: 0.3889 - val_accuracy: 0.8377\n",
      "Epoch 7/50\n",
      "540/547 [============================>.] - ETA: 0s - loss: 0.3469 - accuracy: 0.8510\n",
      "Epoch 7: val_accuracy improved from 0.86453 to 0.86613, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "547/547 [==============================] - 3s 6ms/step - loss: 0.3463 - accuracy: 0.8513 - val_loss: 0.3264 - val_accuracy: 0.8661\n",
      "Epoch 8/50\n",
      "542/547 [============================>.] - ETA: 0s - loss: 0.3445 - accuracy: 0.8547\n",
      "Epoch 8: val_accuracy did not improve from 0.86613\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3448 - accuracy: 0.8546 - val_loss: 0.3855 - val_accuracy: 0.8367\n",
      "Epoch 9/50\n",
      "541/547 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8577\n",
      "Epoch 9: val_accuracy did not improve from 0.86613\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3354 - accuracy: 0.8581 - val_loss: 0.3470 - val_accuracy: 0.8625\n",
      "Epoch 10/50\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.3351 - accuracy: 0.8551\n",
      "Epoch 10: val_accuracy did not improve from 0.86613\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3350 - accuracy: 0.8553 - val_loss: 0.3189 - val_accuracy: 0.8651\n",
      "Epoch 11/50\n",
      "547/547 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.8602\n",
      "Epoch 11: val_accuracy did not improve from 0.86613\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3285 - accuracy: 0.8602 - val_loss: 0.3717 - val_accuracy: 0.8249\n",
      "Epoch 12/50\n",
      "541/547 [============================>.] - ETA: 0s - loss: 0.3249 - accuracy: 0.8642\n",
      "Epoch 12: val_accuracy did not improve from 0.86613\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3259 - accuracy: 0.8639 - val_loss: 0.3626 - val_accuracy: 0.8437\n",
      "Epoch 13/50\n",
      "539/547 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8625\n",
      "Epoch 13: val_accuracy improved from 0.86613 to 0.86667, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "547/547 [==============================] - 3s 6ms/step - loss: 0.3242 - accuracy: 0.8623 - val_loss: 0.3222 - val_accuracy: 0.8667\n",
      "Epoch 14/50\n",
      "535/547 [============================>.] - ETA: 0s - loss: 0.3209 - accuracy: 0.8654\n",
      "Epoch 14: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3203 - accuracy: 0.8656 - val_loss: 0.3239 - val_accuracy: 0.8648\n",
      "Epoch 15/50\n",
      "538/547 [============================>.] - ETA: 0s - loss: 0.3171 - accuracy: 0.8668\n",
      "Epoch 15: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3163 - accuracy: 0.8676 - val_loss: 0.3229 - val_accuracy: 0.8657\n",
      "Epoch 16/50\n",
      "544/547 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.8687\n",
      "Epoch 16: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3122 - accuracy: 0.8689 - val_loss: 0.3596 - val_accuracy: 0.8489\n",
      "Epoch 17/50\n",
      "540/547 [============================>.] - ETA: 0s - loss: 0.3045 - accuracy: 0.8705\n",
      "Epoch 17: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3039 - accuracy: 0.8703 - val_loss: 0.3525 - val_accuracy: 0.8551\n",
      "Epoch 18/50\n",
      "535/547 [============================>.] - ETA: 0s - loss: 0.3012 - accuracy: 0.8724\n",
      "Epoch 18: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3011 - accuracy: 0.8724 - val_loss: 0.3313 - val_accuracy: 0.8659\n",
      "Epoch 19/50\n",
      "535/547 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.8717\n",
      "Epoch 19: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.3020 - accuracy: 0.8724 - val_loss: 0.3385 - val_accuracy: 0.8628\n",
      "Epoch 20/50\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.2956 - accuracy: 0.8751\n",
      "Epoch 20: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2955 - accuracy: 0.8753 - val_loss: 0.3258 - val_accuracy: 0.8605\n",
      "Epoch 21/50\n",
      "547/547 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.8755\n",
      "Epoch 21: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2957 - accuracy: 0.8755 - val_loss: 0.4296 - val_accuracy: 0.8495\n",
      "Epoch 22/50\n",
      "546/547 [============================>.] - ETA: 0s - loss: 0.2911 - accuracy: 0.8769\n",
      "Epoch 22: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2910 - accuracy: 0.8769 - val_loss: 0.3441 - val_accuracy: 0.8585\n",
      "Epoch 23/50\n",
      "542/547 [============================>.] - ETA: 0s - loss: 0.2863 - accuracy: 0.8785\n",
      "Epoch 23: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2861 - accuracy: 0.8789 - val_loss: 0.3348 - val_accuracy: 0.8664\n",
      "Epoch 24/50\n",
      "536/547 [============================>.] - ETA: 0s - loss: 0.2825 - accuracy: 0.8805\n",
      "Epoch 24: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2829 - accuracy: 0.8801 - val_loss: 0.3764 - val_accuracy: 0.8559\n",
      "Epoch 25/50\n",
      "540/547 [============================>.] - ETA: 0s - loss: 0.2772 - accuracy: 0.8840\n",
      "Epoch 25: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2772 - accuracy: 0.8842 - val_loss: 0.3357 - val_accuracy: 0.8664\n",
      "Epoch 26/50\n",
      "542/547 [============================>.] - ETA: 0s - loss: 0.2749 - accuracy: 0.8827\n",
      "Epoch 26: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2751 - accuracy: 0.8825 - val_loss: 0.3469 - val_accuracy: 0.8613\n",
      "Epoch 27/50\n",
      "532/547 [============================>.] - ETA: 0s - loss: 0.2697 - accuracy: 0.8858\n",
      "Epoch 27: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2700 - accuracy: 0.8858 - val_loss: 0.3596 - val_accuracy: 0.8664\n",
      "Epoch 28/50\n",
      "542/547 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.8843\n",
      "Epoch 28: val_accuracy did not improve from 0.86667\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2723 - accuracy: 0.8849 - val_loss: 0.3576 - val_accuracy: 0.8639\n",
      "Epoch 29/50\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.2636 - accuracy: 0.8912\n",
      "Epoch 29: val_accuracy improved from 0.86667 to 0.86987, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "547/547 [==============================] - 3s 6ms/step - loss: 0.2635 - accuracy: 0.8913 - val_loss: 0.3441 - val_accuracy: 0.8699\n",
      "Epoch 30/50\n",
      "539/547 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.8914\n",
      "Epoch 30: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2604 - accuracy: 0.8910 - val_loss: 0.3542 - val_accuracy: 0.8545\n",
      "Epoch 31/50\n",
      "536/547 [============================>.] - ETA: 0s - loss: 0.2565 - accuracy: 0.8916\n",
      "Epoch 31: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2568 - accuracy: 0.8916 - val_loss: 0.3688 - val_accuracy: 0.8567\n",
      "Epoch 32/50\n",
      "533/547 [============================>.] - ETA: 0s - loss: 0.2520 - accuracy: 0.8941\n",
      "Epoch 32: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2520 - accuracy: 0.8943 - val_loss: 0.3814 - val_accuracy: 0.8593\n",
      "Epoch 33/50\n",
      "544/547 [============================>.] - ETA: 0s - loss: 0.2496 - accuracy: 0.8951\n",
      "Epoch 33: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2499 - accuracy: 0.8950 - val_loss: 0.3858 - val_accuracy: 0.8547\n",
      "Epoch 34/50\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.2493 - accuracy: 0.8949\n",
      "Epoch 34: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2489 - accuracy: 0.8953 - val_loss: 0.3727 - val_accuracy: 0.8643\n",
      "Epoch 35/50\n",
      "539/547 [============================>.] - ETA: 0s - loss: 0.2411 - accuracy: 0.8955\n",
      "Epoch 35: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2412 - accuracy: 0.8954 - val_loss: 0.4128 - val_accuracy: 0.8536\n",
      "Epoch 36/50\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.8972\n",
      "Epoch 36: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2453 - accuracy: 0.8971 - val_loss: 0.4223 - val_accuracy: 0.8535\n",
      "Epoch 37/50\n",
      "535/547 [============================>.] - ETA: 0s - loss: 0.2313 - accuracy: 0.9030\n",
      "Epoch 37: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2318 - accuracy: 0.9031 - val_loss: 0.3735 - val_accuracy: 0.8620\n",
      "Epoch 38/50\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.2323 - accuracy: 0.9022\n",
      "Epoch 38: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2323 - accuracy: 0.9020 - val_loss: 0.4438 - val_accuracy: 0.8617\n",
      "Epoch 39/50\n",
      "546/547 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9052\n",
      "Epoch 39: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2288 - accuracy: 0.9053 - val_loss: 0.3859 - val_accuracy: 0.8569\n",
      "Epoch 40/50\n",
      "534/547 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9033\n",
      "Epoch 40: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2286 - accuracy: 0.9033 - val_loss: 0.4140 - val_accuracy: 0.8432\n",
      "Epoch 41/50\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9053\n",
      "Epoch 41: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2214 - accuracy: 0.9054 - val_loss: 0.4442 - val_accuracy: 0.8549\n",
      "Epoch 42/50\n",
      "541/547 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9087\n",
      "Epoch 42: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2163 - accuracy: 0.9087 - val_loss: 0.4892 - val_accuracy: 0.8536\n",
      "Epoch 43/50\n",
      "545/547 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9066\n",
      "Epoch 43: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2169 - accuracy: 0.9066 - val_loss: 0.4716 - val_accuracy: 0.8655\n",
      "Epoch 44/50\n",
      "544/547 [============================>.] - ETA: 0s - loss: 0.2194 - accuracy: 0.9108\n",
      "Epoch 44: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2190 - accuracy: 0.9109 - val_loss: 0.4800 - val_accuracy: 0.8513\n",
      "Epoch 45/50\n",
      "537/547 [============================>.] - ETA: 0s - loss: 0.2119 - accuracy: 0.9118\n",
      "Epoch 45: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2120 - accuracy: 0.9117 - val_loss: 0.4170 - val_accuracy: 0.8636\n",
      "Epoch 46/50\n",
      "547/547 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9155\n",
      "Epoch 46: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2003 - accuracy: 0.9155 - val_loss: 0.4326 - val_accuracy: 0.8585\n",
      "Epoch 47/50\n",
      "533/547 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9167\n",
      "Epoch 47: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.1987 - accuracy: 0.9162 - val_loss: 0.4588 - val_accuracy: 0.8563\n",
      "Epoch 48/50\n",
      "534/547 [============================>.] - ETA: 0s - loss: 0.2072 - accuracy: 0.9126\n",
      "Epoch 48: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.2069 - accuracy: 0.9125 - val_loss: 0.4512 - val_accuracy: 0.8491\n",
      "Epoch 49/50\n",
      "543/547 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9189\n",
      "Epoch 49: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.1936 - accuracy: 0.9187 - val_loss: 0.4790 - val_accuracy: 0.8620\n",
      "Epoch 50/50\n",
      "540/547 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.9199\n",
      "Epoch 50: val_accuracy did not improve from 0.86987\n",
      "547/547 [==============================] - 2s 4ms/step - loss: 0.1896 - accuracy: 0.9200 - val_loss: 0.4511 - val_accuracy: 0.8509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2670f75af70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compile(optimizer=SGD(momentum=0.02), loss=BinaryCrossentropy(), metrics='accuracy')\n",
    "model.compile('adam', loss=BinaryCrossentropy(), metrics='accuracy')\n",
    "\n",
    "model.fit(x=train_x,\n",
    "         y=train_y,\n",
    "         batch_size=32,\n",
    "         epochs=50,\n",
    "         validation_split=0.3,\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b586030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c315d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value(row):\n",
    "    if (row == 0):\n",
    "        return '+'\n",
    "    elif (row == 1) :\n",
    "        return '-'\n",
    "\n",
    "def remap(y):\n",
    "    res= y.argmax(axis=1)\n",
    "    df = pd.DataFrame(res, columns=['Predicted'])\n",
    "    df['Predicted'] = df['Predicted'].apply(change_value)\n",
    "    return df\n",
    "\n",
    "def predict_result(model, x):    \n",
    "    y_pred = model.predict(x)\n",
    "    return remap(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72707a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_result(model, train_x)\n",
    "y_true = remap(train_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6c823be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.87508\n",
      "f1: 0.8750799999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"acc: {accuracy_score(y_pred,y_true)}\")\n",
    "print(f\"f1: {f1_score(y_pred,y_true, average='micro')}\")              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7385cbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x25821baec10>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d46c26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_result(model, test_x)\n",
    "y_true = remap(test_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a562d1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.85748\n",
      "f1: 0.85748\n"
     ]
    }
   ],
   "source": [
    "print(f\"acc: {accuracy_score(y_pred,y_true)}\")\n",
    "print(f\"f1: {f1_score(y_pred,y_true, average='micro')}\")              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5821b950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2581230bfa0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f447aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.to_csv('./train_x.csv', index=False)\n",
    "train_y.to_csv('./train_y.csv', index=False)\n",
    "test_x.to_csv('./test_x.csv', index=False)\n",
    "test_y.to_csv('./test_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d719e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
