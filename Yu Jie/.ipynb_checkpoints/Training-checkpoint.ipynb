{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36a766c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "\n",
    "tqdm.pandas()\n",
    "spacy.require_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95749cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2492f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_directory = '../processed_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3f6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('../processed_data/train.json')\n",
    "test_df = pd.read_json('../processed_data/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d586b5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11041</td>\n",
       "      <td>The show is average. It doesn't make me laugh ...</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5342</td>\n",
       "      <td>Rachel, Jo, Hannah, Tina, Bradley and John are...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9255</td>\n",
       "      <td>First, I should mention that I really enjoyed ...</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7152</td>\n",
       "      <td>'Holes' was a GREAT movie. Disney made the rig...</td>\n",
       "      <td>9</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11383</td>\n",
       "      <td>This is a fine musical with a timeless score b...</td>\n",
       "      <td>7</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>2979</td>\n",
       "      <td>There really isn't much to say about this movi...</td>\n",
       "      <td>10</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>9462</td>\n",
       "      <td>Clean family oriented movie. I laughed, I crie...</td>\n",
       "      <td>9</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>3995</td>\n",
       "      <td>'1408' is the latest hodge podge of cheap scar...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>11960</td>\n",
       "      <td>\"Scoop\" is also the name of a late-Thirties Ev...</td>\n",
       "      <td>8</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>10722</td>\n",
       "      <td>**SPOILERS*** Slow as molasses mummy movie inv...</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  rating label\n",
       "0      11041  The show is average. It doesn't make me laugh ...       4     -\n",
       "1       5342  Rachel, Jo, Hannah, Tina, Bradley and John are...       1     -\n",
       "2       9255  First, I should mention that I really enjoyed ...       2     -\n",
       "3       7152  'Holes' was a GREAT movie. Disney made the rig...       9     +\n",
       "4      11383  This is a fine musical with a timeless score b...       7     +\n",
       "...      ...                                                ...     ...   ...\n",
       "24995   2979  There really isn't much to say about this movi...      10     +\n",
       "24996   9462  Clean family oriented movie. I laughed, I crie...       9     +\n",
       "24997   3995  '1408' is the latest hodge podge of cheap scar...       1     -\n",
       "24998  11960  \"Scoop\" is also the name of a late-Thirties Ev...       8     +\n",
       "24999  10722  **SPOILERS*** Slow as molasses mummy movie inv...       4     -\n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edcbbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>10</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>7</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>9</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>8</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>8</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>9998</td>\n",
       "      <td>I occasionally let my kids watch this garbage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>9999</td>\n",
       "      <td>When all we have anymore is pretty much realit...</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>999</td>\n",
       "      <td>The basic genre is a thriller intercut with an...</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>99</td>\n",
       "      <td>Four things intrigued me as to this film - fir...</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>9</td>\n",
       "      <td>David Bryce's comments nearby are exceptionall...</td>\n",
       "      <td>4</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  rating label\n",
       "0          0  I went and saw this movie last night after bei...      10     +\n",
       "1      10000  Actor turned director Bill Paxton follows up h...       7     +\n",
       "2      10001  As a recreational golfer with some knowledge o...       9     +\n",
       "3      10002  I saw this film in a sneak preview, and it is ...       8     +\n",
       "4      10003  Bill Paxton has taken the true story of the 19...       8     +\n",
       "...      ...                                                ...     ...   ...\n",
       "24995   9998  I occasionally let my kids watch this garbage ...       1     -\n",
       "24996   9999  When all we have anymore is pretty much realit...       1     -\n",
       "24997    999  The basic genre is a thriller intercut with an...       3     -\n",
       "24998     99  Four things intrigued me as to this film - fir...       3     -\n",
       "24999      9  David Bryce's comments nearby are exceptionall...       4     -\n",
       "\n",
       "[25000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6eff201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1559ac28be0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1559ac65160>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1559471e820>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1559acf70c0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1559acfcf40>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1559471e7b0>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e76b824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(text, nlp):\n",
    "    doc = nlp(text)\n",
    "    return doc.vector\n",
    "\n",
    "def get_features(df):\n",
    "    text_list = df['text'].to_list()\n",
    "    x = []\n",
    "    for doc in tqdm_notebook(nlp.pipe(text_list, disable=[\"tagger\", \"parser\", \"lemmatizer\", 'attribute_ruler', 'ner'])):\n",
    "        x.append(doc.vector)\n",
    "    x = pd.DataFrame(x)\n",
    "    y = df['label']\n",
    "    y = pd.get_dummies(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b73ed6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25000it [01:49, 228.10it/s]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = get_features(train_df)\n",
    "test_x, test_y = get_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0a04d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.astype('float32')\n",
    "test_x = test_x.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9e92a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.098653</td>\n",
       "      <td>0.237332</td>\n",
       "      <td>-0.227549</td>\n",
       "      <td>-0.059897</td>\n",
       "      <td>0.041167</td>\n",
       "      <td>0.053954</td>\n",
       "      <td>0.041598</td>\n",
       "      <td>-0.212204</td>\n",
       "      <td>-0.030462</td>\n",
       "      <td>2.288359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080512</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>-0.020111</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>0.052879</td>\n",
       "      <td>0.042916</td>\n",
       "      <td>-0.025879</td>\n",
       "      <td>-0.042477</td>\n",
       "      <td>0.055505</td>\n",
       "      <td>0.032498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.056069</td>\n",
       "      <td>0.164208</td>\n",
       "      <td>-0.111401</td>\n",
       "      <td>-0.112217</td>\n",
       "      <td>0.082695</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>-0.160687</td>\n",
       "      <td>-0.034788</td>\n",
       "      <td>2.044537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165167</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>-0.042601</td>\n",
       "      <td>-0.053598</td>\n",
       "      <td>0.078946</td>\n",
       "      <td>0.026528</td>\n",
       "      <td>-0.003979</td>\n",
       "      <td>-0.089736</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>0.031012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.025594</td>\n",
       "      <td>0.173807</td>\n",
       "      <td>-0.113592</td>\n",
       "      <td>-0.080288</td>\n",
       "      <td>0.121748</td>\n",
       "      <td>0.046220</td>\n",
       "      <td>0.017448</td>\n",
       "      <td>-0.121140</td>\n",
       "      <td>-0.023063</td>\n",
       "      <td>1.976007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173515</td>\n",
       "      <td>0.041926</td>\n",
       "      <td>0.017024</td>\n",
       "      <td>-0.010830</td>\n",
       "      <td>0.033183</td>\n",
       "      <td>0.007571</td>\n",
       "      <td>-0.033585</td>\n",
       "      <td>-0.045075</td>\n",
       "      <td>-0.011756</td>\n",
       "      <td>0.023251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.026709</td>\n",
       "      <td>0.228059</td>\n",
       "      <td>-0.154029</td>\n",
       "      <td>-0.129077</td>\n",
       "      <td>0.087855</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>0.082640</td>\n",
       "      <td>-0.213129</td>\n",
       "      <td>-0.046223</td>\n",
       "      <td>2.200672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098601</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>-0.006471</td>\n",
       "      <td>-0.035367</td>\n",
       "      <td>0.128100</td>\n",
       "      <td>-0.073214</td>\n",
       "      <td>-0.107157</td>\n",
       "      <td>-0.002758</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.104389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016726</td>\n",
       "      <td>0.186435</td>\n",
       "      <td>-0.135161</td>\n",
       "      <td>-0.096413</td>\n",
       "      <td>0.078521</td>\n",
       "      <td>0.070652</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>-0.179566</td>\n",
       "      <td>-0.033138</td>\n",
       "      <td>1.932208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181982</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.040958</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.036744</td>\n",
       "      <td>0.055756</td>\n",
       "      <td>-0.035302</td>\n",
       "      <td>-0.084084</td>\n",
       "      <td>-0.013650</td>\n",
       "      <td>0.137881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>-0.048090</td>\n",
       "      <td>0.150734</td>\n",
       "      <td>-0.123009</td>\n",
       "      <td>-0.092647</td>\n",
       "      <td>0.115555</td>\n",
       "      <td>0.020735</td>\n",
       "      <td>0.023961</td>\n",
       "      <td>-0.114092</td>\n",
       "      <td>0.011440</td>\n",
       "      <td>1.860095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152963</td>\n",
       "      <td>-0.000891</td>\n",
       "      <td>-0.026846</td>\n",
       "      <td>-0.014160</td>\n",
       "      <td>0.028144</td>\n",
       "      <td>0.015263</td>\n",
       "      <td>-0.062839</td>\n",
       "      <td>-0.095883</td>\n",
       "      <td>-0.006639</td>\n",
       "      <td>0.062071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>-0.017593</td>\n",
       "      <td>0.180526</td>\n",
       "      <td>-0.135005</td>\n",
       "      <td>-0.160613</td>\n",
       "      <td>0.102259</td>\n",
       "      <td>0.020344</td>\n",
       "      <td>0.046305</td>\n",
       "      <td>-0.236645</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>2.176674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132983</td>\n",
       "      <td>0.009750</td>\n",
       "      <td>-0.024606</td>\n",
       "      <td>-0.018269</td>\n",
       "      <td>0.093126</td>\n",
       "      <td>-0.020145</td>\n",
       "      <td>-0.034903</td>\n",
       "      <td>-0.032044</td>\n",
       "      <td>0.034915</td>\n",
       "      <td>0.105352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.137014</td>\n",
       "      <td>-0.122286</td>\n",
       "      <td>-0.069232</td>\n",
       "      <td>0.090511</td>\n",
       "      <td>0.021604</td>\n",
       "      <td>-0.009902</td>\n",
       "      <td>-0.085119</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>2.144040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190512</td>\n",
       "      <td>0.064347</td>\n",
       "      <td>-0.009885</td>\n",
       "      <td>-0.021734</td>\n",
       "      <td>0.027786</td>\n",
       "      <td>0.033115</td>\n",
       "      <td>-0.042924</td>\n",
       "      <td>-0.037416</td>\n",
       "      <td>0.026347</td>\n",
       "      <td>0.049002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>-0.032313</td>\n",
       "      <td>0.183513</td>\n",
       "      <td>-0.095211</td>\n",
       "      <td>-0.022576</td>\n",
       "      <td>0.099779</td>\n",
       "      <td>0.036688</td>\n",
       "      <td>0.028060</td>\n",
       "      <td>-0.141543</td>\n",
       "      <td>-0.052280</td>\n",
       "      <td>1.960207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123420</td>\n",
       "      <td>0.027996</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>-0.013598</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>0.016152</td>\n",
       "      <td>-0.016169</td>\n",
       "      <td>-0.075711</td>\n",
       "      <td>-0.018939</td>\n",
       "      <td>0.019662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>-0.001639</td>\n",
       "      <td>0.120283</td>\n",
       "      <td>-0.084706</td>\n",
       "      <td>-0.063833</td>\n",
       "      <td>0.061360</td>\n",
       "      <td>0.042077</td>\n",
       "      <td>-0.008926</td>\n",
       "      <td>-0.100593</td>\n",
       "      <td>-0.043038</td>\n",
       "      <td>1.939081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113291</td>\n",
       "      <td>0.018487</td>\n",
       "      <td>-0.026250</td>\n",
       "      <td>-0.059459</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.007492</td>\n",
       "      <td>-0.023138</td>\n",
       "      <td>0.023410</td>\n",
       "      <td>-0.011980</td>\n",
       "      <td>-0.014129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0     -0.098653  0.237332 -0.227549 -0.059897  0.041167  0.053954  0.041598   \n",
       "1     -0.056069  0.164208 -0.111401 -0.112217  0.082695  0.010604  0.085113   \n",
       "2     -0.025594  0.173807 -0.113592 -0.080288  0.121748  0.046220  0.017448   \n",
       "3     -0.026709  0.228059 -0.154029 -0.129077  0.087855 -0.003604  0.082640   \n",
       "4      0.016726  0.186435 -0.135161 -0.096413  0.078521  0.070652  0.035408   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "24995 -0.048090  0.150734 -0.123009 -0.092647  0.115555  0.020735  0.023961   \n",
       "24996 -0.017593  0.180526 -0.135005 -0.160613  0.102259  0.020344  0.046305   \n",
       "24997  0.001822  0.137014 -0.122286 -0.069232  0.090511  0.021604 -0.009902   \n",
       "24998 -0.032313  0.183513 -0.095211 -0.022576  0.099779  0.036688  0.028060   \n",
       "24999 -0.001639  0.120283 -0.084706 -0.063833  0.061360  0.042077 -0.008926   \n",
       "\n",
       "            7         8         9    ...       290       291       292  \\\n",
       "0     -0.212204 -0.030462  2.288359  ... -0.080512  0.013579 -0.020111   \n",
       "1     -0.160687 -0.034788  2.044537  ... -0.165167  0.016225 -0.042601   \n",
       "2     -0.121140 -0.023063  1.976007  ... -0.173515  0.041926  0.017024   \n",
       "3     -0.213129 -0.046223  2.200672  ... -0.098601  0.031794 -0.006471   \n",
       "4     -0.179566 -0.033138  1.932208  ... -0.181982  0.011574  0.040958   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "24995 -0.114092  0.011440  1.860095  ... -0.152963 -0.000891 -0.026846   \n",
       "24996 -0.236645  0.012075  2.176674  ... -0.132983  0.009750 -0.024606   \n",
       "24997 -0.085119  0.006140  2.144040  ... -0.190512  0.064347 -0.009885   \n",
       "24998 -0.141543 -0.052280  1.960207  ... -0.123420  0.027996  0.019448   \n",
       "24999 -0.100593 -0.043038  1.939081  ... -0.113291  0.018487 -0.026250   \n",
       "\n",
       "            293       294       295       296       297       298       299  \n",
       "0     -0.011932  0.052879  0.042916 -0.025879 -0.042477  0.055505  0.032498  \n",
       "1     -0.053598  0.078946  0.026528 -0.003979 -0.089736  0.024499  0.031012  \n",
       "2     -0.010830  0.033183  0.007571 -0.033585 -0.045075 -0.011756  0.023251  \n",
       "3     -0.035367  0.128100 -0.073214 -0.107157 -0.002758  0.005043  0.104389  \n",
       "4      0.000037  0.036744  0.055756 -0.035302 -0.084084 -0.013650  0.137881  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "24995 -0.014160  0.028144  0.015263 -0.062839 -0.095883 -0.006639  0.062071  \n",
       "24996 -0.018269  0.093126 -0.020145 -0.034903 -0.032044  0.034915  0.105352  \n",
       "24997 -0.021734  0.027786  0.033115 -0.042924 -0.037416  0.026347  0.049002  \n",
       "24998 -0.013598  0.019727  0.016152 -0.016169 -0.075711 -0.018939  0.019662  \n",
       "24999 -0.059459  0.010273  0.007492 -0.023138  0.023410 -0.011980 -0.014129  \n",
       "\n",
       "[25000 rows x 300 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d0f64ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       +  -\n",
       "0      0  1\n",
       "1      0  1\n",
       "2      0  1\n",
       "3      1  0\n",
       "4      1  0\n",
       "...   .. ..\n",
       "24995  1  0\n",
       "24996  1  0\n",
       "24997  0  1\n",
       "24998  1  0\n",
       "24999  0  1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bfeec18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(512, input_shape=(300,), activation='relu'),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])\n",
    "callbacks=[\n",
    "    ModelCheckpoint(filepath='./models/checkpoint',\n",
    "                   save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4143131b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.6925\n",
      "Epoch 1: val_loss improved from inf to 0.69001, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 3s 15ms/step - loss: 0.6925 - val_loss: 0.6900\n",
      "Epoch 2/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.6899\n",
      "Epoch 2: val_loss improved from 0.69001 to 0.68644, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.6898 - val_loss: 0.6864\n",
      "Epoch 3/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.6866\n",
      "Epoch 3: val_loss improved from 0.68644 to 0.68183, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 2s 11ms/step - loss: 0.6865 - val_loss: 0.6818\n",
      "Epoch 4/300\n",
      "122/137 [=========================>....] - ETA: 0s - loss: 0.6829\n",
      "Epoch 4: val_loss improved from 0.68183 to 0.67561, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.6826 - val_loss: 0.6756\n",
      "Epoch 5/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.6771\n",
      "Epoch 5: val_loss improved from 0.67561 to 0.66699, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6767 - val_loss: 0.6670\n",
      "Epoch 6/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.6668\n",
      "Epoch 6: val_loss improved from 0.66699 to 0.65445, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 0.6669 - val_loss: 0.6544\n",
      "Epoch 7/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.6525\n",
      "Epoch 7: val_loss improved from 0.65445 to 0.63502, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.6524 - val_loss: 0.6350\n",
      "Epoch 8/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.6294\n",
      "Epoch 8: val_loss improved from 0.63502 to 0.60674, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.6295 - val_loss: 0.6067\n",
      "Epoch 9/300\n",
      "122/137 [=========================>....] - ETA: 0s - loss: 0.6006\n",
      "Epoch 9: val_loss improved from 0.60674 to 0.58443, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.5986 - val_loss: 0.5844\n",
      "Epoch 10/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.5636\n",
      "Epoch 10: val_loss improved from 0.58443 to 0.53924, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 11ms/step - loss: 0.5616 - val_loss: 0.5392\n",
      "Epoch 11/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.5268\n",
      "Epoch 11: val_loss improved from 0.53924 to 0.49330, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 0.5266 - val_loss: 0.4933\n",
      "Epoch 12/300\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 0.5287\n",
      "Epoch 12: val_loss did not improve from 0.49330\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.5276 - val_loss: 0.5264\n",
      "Epoch 13/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.5092\n",
      "Epoch 13: val_loss did not improve from 0.49330\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.5106 - val_loss: 0.5317\n",
      "Epoch 14/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.5042\n",
      "Epoch 14: val_loss improved from 0.49330 to 0.45442, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.5021 - val_loss: 0.4544\n",
      "Epoch 15/300\n",
      "123/137 [=========================>....] - ETA: 0s - loss: 0.4891\n",
      "Epoch 15: val_loss improved from 0.45442 to 0.43373, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 0.4868 - val_loss: 0.4337\n",
      "Epoch 16/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.4853\n",
      "Epoch 16: val_loss did not improve from 0.43373\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4889 - val_loss: 0.5318\n",
      "Epoch 17/300\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 0.4646\n",
      "Epoch 17: val_loss did not improve from 0.43373\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4662 - val_loss: 0.4752\n",
      "Epoch 18/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.4667\n",
      "Epoch 18: val_loss did not improve from 0.43373\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4671 - val_loss: 0.5261\n",
      "Epoch 19/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.4549\n",
      "Epoch 19: val_loss improved from 0.43373 to 0.42041, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.4545 - val_loss: 0.4204\n",
      "Epoch 20/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.4470\n",
      "Epoch 20: val_loss improved from 0.42041 to 0.41952, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.4480 - val_loss: 0.4195\n",
      "Epoch 21/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.4520\n",
      "Epoch 21: val_loss did not improve from 0.41952\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.4517 - val_loss: 0.4916\n",
      "Epoch 22/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.4384\n",
      "Epoch 22: val_loss did not improve from 0.41952\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4378 - val_loss: 0.4282\n",
      "Epoch 23/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.4440\n",
      "Epoch 23: val_loss improved from 0.41952 to 0.38981, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 0.4435 - val_loss: 0.3898\n",
      "Epoch 24/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.4272\n",
      "Epoch 24: val_loss did not improve from 0.38981\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4265 - val_loss: 0.4056\n",
      "Epoch 25/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.4314\n",
      "Epoch 25: val_loss did not improve from 0.38981\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4322 - val_loss: 0.5026\n",
      "Epoch 26/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.4223\n",
      "Epoch 26: val_loss did not improve from 0.38981\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4246 - val_loss: 0.4442\n",
      "Epoch 27/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.4305\n",
      "Epoch 27: val_loss improved from 0.38981 to 0.38739, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.4272 - val_loss: 0.3874\n",
      "Epoch 28/300\n",
      "123/137 [=========================>....] - ETA: 0s - loss: 0.4182\n",
      "Epoch 28: val_loss did not improve from 0.38739\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.4176 - val_loss: 0.4086\n",
      "Epoch 29/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.4162\n",
      "Epoch 29: val_loss improved from 0.38739 to 0.38162, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 0.4162 - val_loss: 0.3816\n",
      "Epoch 30/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.4082\n",
      "Epoch 30: val_loss improved from 0.38162 to 0.37239, saving model to ./models\\checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 0.4070 - val_loss: 0.3724\n",
      "Epoch 31/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.4144\n",
      "Epoch 31: val_loss did not improve from 0.37239\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4176 - val_loss: 0.5616\n",
      "Epoch 32/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.4109\n",
      "Epoch 32: val_loss did not improve from 0.37239\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4119 - val_loss: 0.5786\n",
      "Epoch 33/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.4051\n",
      "Epoch 33: val_loss improved from 0.37239 to 0.36926, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.4031 - val_loss: 0.3693\n",
      "Epoch 34/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.4099\n",
      "Epoch 34: val_loss improved from 0.36926 to 0.36771, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 0.4078 - val_loss: 0.3677\n",
      "Epoch 35/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.4026\n",
      "Epoch 35: val_loss did not improve from 0.36771\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4025 - val_loss: 0.3747\n",
      "Epoch 36/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3983\n",
      "Epoch 36: val_loss did not improve from 0.36771\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3980 - val_loss: 0.3779\n",
      "Epoch 37/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3963\n",
      "Epoch 37: val_loss improved from 0.36771 to 0.36698, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3963 - val_loss: 0.3670\n",
      "Epoch 38/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3975\n",
      "Epoch 38: val_loss did not improve from 0.36698\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3963 - val_loss: 0.4739\n",
      "Epoch 39/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.4039\n",
      "Epoch 39: val_loss did not improve from 0.36698\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.4045 - val_loss: 0.3804\n",
      "Epoch 40/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3939\n",
      "Epoch 40: val_loss did not improve from 0.36698\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3899 - val_loss: 0.3833\n",
      "Epoch 41/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3939\n",
      "Epoch 41: val_loss did not improve from 0.36698\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3928 - val_loss: 0.3974\n",
      "Epoch 42/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3878\n",
      "Epoch 42: val_loss improved from 0.36698 to 0.36042, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3863 - val_loss: 0.3604\n",
      "Epoch 43/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3896\n",
      "Epoch 43: val_loss did not improve from 0.36042\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3900 - val_loss: 0.3609\n",
      "Epoch 44/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3908\n",
      "Epoch 44: val_loss did not improve from 0.36042\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3914 - val_loss: 0.4074\n",
      "Epoch 45/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3857\n",
      "Epoch 45: val_loss did not improve from 0.36042\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3854 - val_loss: 0.4649\n",
      "Epoch 46/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3883\n",
      "Epoch 46: val_loss did not improve from 0.36042\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3862 - val_loss: 0.3776\n",
      "Epoch 47/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3873\n",
      "Epoch 47: val_loss did not improve from 0.36042\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3883 - val_loss: 0.4397\n",
      "Epoch 48/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3787\n",
      "Epoch 48: val_loss did not improve from 0.36042\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3790 - val_loss: 0.3606\n",
      "Epoch 49/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3828\n",
      "Epoch 49: val_loss did not improve from 0.36042\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3833 - val_loss: 0.3812\n",
      "Epoch 50/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3772\n",
      "Epoch 50: val_loss did not improve from 0.36042\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3768 - val_loss: 0.3679\n",
      "Epoch 51/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3781\n",
      "Epoch 51: val_loss improved from 0.36042 to 0.35239, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 0.3770 - val_loss: 0.3524\n",
      "Epoch 52/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3834\n",
      "Epoch 52: val_loss did not improve from 0.35239\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3827 - val_loss: 0.4177\n",
      "Epoch 53/300\n",
      "123/137 [=========================>....] - ETA: 0s - loss: 0.3801\n",
      "Epoch 53: val_loss did not improve from 0.35239\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3783 - val_loss: 0.3668\n",
      "Epoch 54/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3753\n",
      "Epoch 54: val_loss did not improve from 0.35239\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3782 - val_loss: 0.4220\n",
      "Epoch 55/300\n",
      "123/137 [=========================>....] - ETA: 0s - loss: 0.3701\n",
      "Epoch 55: val_loss did not improve from 0.35239\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3716 - val_loss: 0.3558\n",
      "Epoch 56/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3779\n",
      "Epoch 56: val_loss improved from 0.35239 to 0.35142, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3774 - val_loss: 0.3514\n",
      "Epoch 57/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3779\n",
      "Epoch 57: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3753 - val_loss: 0.3534\n",
      "Epoch 58/300\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 0.3693\n",
      "Epoch 58: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3682 - val_loss: 0.3871\n",
      "Epoch 59/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3761\n",
      "Epoch 59: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3765 - val_loss: 0.3789\n",
      "Epoch 60/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3718\n",
      "Epoch 60: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3742 - val_loss: 0.5479\n",
      "Epoch 61/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3711\n",
      "Epoch 61: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3707 - val_loss: 0.3585\n",
      "Epoch 62/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3755\n",
      "Epoch 62: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3757 - val_loss: 0.3605\n",
      "Epoch 63/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3644\n",
      "Epoch 63: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3639 - val_loss: 0.3655\n",
      "Epoch 64/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3686\n",
      "Epoch 64: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3695 - val_loss: 0.3570\n",
      "Epoch 65/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3671\n",
      "Epoch 65: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3661 - val_loss: 0.4311\n",
      "Epoch 66/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3687\n",
      "Epoch 66: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3685 - val_loss: 0.3943\n",
      "Epoch 67/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3636\n",
      "Epoch 67: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3645 - val_loss: 0.3722\n",
      "Epoch 68/300\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 0.3637\n",
      "Epoch 68: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3598 - val_loss: 0.3706\n",
      "Epoch 69/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3674\n",
      "Epoch 69: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3696 - val_loss: 0.3696\n",
      "Epoch 70/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3707\n",
      "Epoch 70: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3702 - val_loss: 0.4876\n",
      "Epoch 71/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3670\n",
      "Epoch 71: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3688 - val_loss: 0.3619\n",
      "Epoch 72/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3599\n",
      "Epoch 72: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3589 - val_loss: 0.3555\n",
      "Epoch 73/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3562\n",
      "Epoch 73: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3554 - val_loss: 0.4174\n",
      "Epoch 74/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3714\n",
      "Epoch 74: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3703 - val_loss: 0.4734\n",
      "Epoch 75/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3667\n",
      "Epoch 75: val_loss did not improve from 0.35142\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3689 - val_loss: 0.3671\n",
      "Epoch 76/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3563\n",
      "Epoch 76: val_loss improved from 0.35142 to 0.34355, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3568 - val_loss: 0.3435\n",
      "Epoch 77/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3608\n",
      "Epoch 77: val_loss did not improve from 0.34355\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3591 - val_loss: 0.4092\n",
      "Epoch 78/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3609\n",
      "Epoch 78: val_loss did not improve from 0.34355\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3646 - val_loss: 0.3530\n",
      "Epoch 79/300\n",
      "122/137 [=========================>....] - ETA: 0s - loss: 0.3639\n",
      "Epoch 79: val_loss did not improve from 0.34355\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3622 - val_loss: 0.4974\n",
      "Epoch 80/300\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 0.3605\n",
      "Epoch 80: val_loss did not improve from 0.34355\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3600 - val_loss: 0.6568\n",
      "Epoch 81/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3634\n",
      "Epoch 81: val_loss did not improve from 0.34355\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3642 - val_loss: 0.3959\n",
      "Epoch 82/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3533\n",
      "Epoch 82: val_loss did not improve from 0.34355\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3530 - val_loss: 0.3517\n",
      "Epoch 83/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3556\n",
      "Epoch 83: val_loss improved from 0.34355 to 0.34161, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3571 - val_loss: 0.3416\n",
      "Epoch 84/300\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 0.3524\n",
      "Epoch 84: val_loss did not improve from 0.34161\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3527 - val_loss: 0.4150\n",
      "Epoch 85/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3555\n",
      "Epoch 85: val_loss did not improve from 0.34161\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3546 - val_loss: 0.3893\n",
      "Epoch 86/300\n",
      "122/137 [=========================>....] - ETA: 0s - loss: 0.3571\n",
      "Epoch 86: val_loss did not improve from 0.34161\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3540 - val_loss: 0.3678\n",
      "Epoch 87/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3521\n",
      "Epoch 87: val_loss did not improve from 0.34161\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3521 - val_loss: 0.3493\n",
      "Epoch 88/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3618\n",
      "Epoch 88: val_loss did not improve from 0.34161\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3611 - val_loss: 0.3419\n",
      "Epoch 89/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3470\n",
      "Epoch 89: val_loss did not improve from 0.34161\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3479 - val_loss: 0.3901\n",
      "Epoch 90/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3484\n",
      "Epoch 90: val_loss improved from 0.34161 to 0.33889, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 2s 18ms/step - loss: 0.3487 - val_loss: 0.3389\n",
      "Epoch 91/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3543\n",
      "Epoch 91: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3554 - val_loss: 0.3512\n",
      "Epoch 92/300\n",
      "122/137 [=========================>....] - ETA: 0s - loss: 0.3543\n",
      "Epoch 92: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 0.3489\n",
      "Epoch 93/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3471\n",
      "Epoch 93: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3478 - val_loss: 0.4020\n",
      "Epoch 94/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3550\n",
      "Epoch 94: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3533 - val_loss: 0.3896\n",
      "Epoch 95/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3604\n",
      "Epoch 95: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3596 - val_loss: 0.3416\n",
      "Epoch 96/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3493\n",
      "Epoch 96: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3490 - val_loss: 0.4138\n",
      "Epoch 97/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3491\n",
      "Epoch 97: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3480 - val_loss: 0.3483\n",
      "Epoch 98/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3440\n",
      "Epoch 98: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3447 - val_loss: 0.3393\n",
      "Epoch 99/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3572\n",
      "Epoch 99: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3572 - val_loss: 0.3715\n",
      "Epoch 100/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3538\n",
      "Epoch 100: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3526 - val_loss: 0.3428\n",
      "Epoch 101/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3512\n",
      "Epoch 101: val_loss did not improve from 0.33889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3534 - val_loss: 0.4049\n",
      "Epoch 102/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3579\n",
      "Epoch 102: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3563 - val_loss: 0.3412\n",
      "Epoch 103/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3443\n",
      "Epoch 103: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3447 - val_loss: 0.3428\n",
      "Epoch 104/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3473\n",
      "Epoch 104: val_loss did not improve from 0.33889\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3461 - val_loss: 0.3831\n",
      "Epoch 105/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3519\n",
      "Epoch 105: val_loss improved from 0.33889 to 0.33763, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3540 - val_loss: 0.3376\n",
      "Epoch 106/300\n",
      "123/137 [=========================>....] - ETA: 0s - loss: 0.3464\n",
      "Epoch 106: val_loss improved from 0.33763 to 0.33589, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 0.3460 - val_loss: 0.3359\n",
      "Epoch 107/300\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 0.3562\n",
      "Epoch 107: val_loss did not improve from 0.33589\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3542 - val_loss: 0.3728\n",
      "Epoch 108/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3435\n",
      "Epoch 108: val_loss did not improve from 0.33589\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3429 - val_loss: 0.3852\n",
      "Epoch 109/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3469\n",
      "Epoch 109: val_loss did not improve from 0.33589\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3474 - val_loss: 0.3904\n",
      "Epoch 110/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3463\n",
      "Epoch 110: val_loss did not improve from 0.33589\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3469 - val_loss: 0.3459\n",
      "Epoch 111/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3482\n",
      "Epoch 111: val_loss improved from 0.33589 to 0.33565, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3473 - val_loss: 0.3357\n",
      "Epoch 112/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3475\n",
      "Epoch 112: val_loss did not improve from 0.33565\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3471 - val_loss: 0.3538\n",
      "Epoch 113/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3479\n",
      "Epoch 113: val_loss did not improve from 0.33565\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3481 - val_loss: 0.3516\n",
      "Epoch 114/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3420\n",
      "Epoch 114: val_loss did not improve from 0.33565\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3437 - val_loss: 0.3747\n",
      "Epoch 115/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3376\n",
      "Epoch 115: val_loss did not improve from 0.33565\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3392 - val_loss: 0.3388\n",
      "Epoch 116/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3462\n",
      "Epoch 116: val_loss improved from 0.33565 to 0.33563, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3460 - val_loss: 0.3356\n",
      "Epoch 117/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3412\n",
      "Epoch 117: val_loss did not improve from 0.33563\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3414 - val_loss: 0.4119\n",
      "Epoch 118/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3433\n",
      "Epoch 118: val_loss did not improve from 0.33563\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3420 - val_loss: 0.3410\n",
      "Epoch 119/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3440\n",
      "Epoch 119: val_loss improved from 0.33563 to 0.33403, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 9ms/step - loss: 0.3446 - val_loss: 0.3340\n",
      "Epoch 120/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3417\n",
      "Epoch 120: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3418 - val_loss: 0.4352\n",
      "Epoch 121/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3436\n",
      "Epoch 121: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3465 - val_loss: 0.3381\n",
      "Epoch 122/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3462\n",
      "Epoch 122: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3459 - val_loss: 0.3728\n",
      "Epoch 123/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3424\n",
      "Epoch 123: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3405 - val_loss: 0.3847\n",
      "Epoch 124/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3429\n",
      "Epoch 124: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3427 - val_loss: 0.3773\n",
      "Epoch 125/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3456\n",
      "Epoch 125: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3464 - val_loss: 0.3343\n",
      "Epoch 126/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3323\n",
      "Epoch 126: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3330 - val_loss: 0.4189\n",
      "Epoch 127/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3393\n",
      "Epoch 127: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3399 - val_loss: 0.3583\n",
      "Epoch 128/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3371\n",
      "Epoch 128: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3362 - val_loss: 0.3796\n",
      "Epoch 129/300\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 0.3420\n",
      "Epoch 129: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3397 - val_loss: 0.3410\n",
      "Epoch 130/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3387\n",
      "Epoch 130: val_loss did not improve from 0.33403\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3393 - val_loss: 0.3467\n",
      "Epoch 131/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3369\n",
      "Epoch 131: val_loss improved from 0.33403 to 0.33306, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3376 - val_loss: 0.3331\n",
      "Epoch 132/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3337\n",
      "Epoch 132: val_loss improved from 0.33306 to 0.33138, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 2s 12ms/step - loss: 0.3353 - val_loss: 0.3314\n",
      "Epoch 133/300\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 0.3436\n",
      "Epoch 133: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3453 - val_loss: 0.3364\n",
      "Epoch 134/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3329\n",
      "Epoch 134: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3325 - val_loss: 0.3331\n",
      "Epoch 135/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3310\n",
      "Epoch 135: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3310 - val_loss: 0.3363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3370\n",
      "Epoch 136: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3376 - val_loss: 0.3324\n",
      "Epoch 137/300\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 0.3413\n",
      "Epoch 137: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3409 - val_loss: 0.3363\n",
      "Epoch 138/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3321\n",
      "Epoch 138: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3327 - val_loss: 0.3845\n",
      "Epoch 139/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3367\n",
      "Epoch 139: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3355 - val_loss: 0.3402\n",
      "Epoch 140/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3368\n",
      "Epoch 140: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3343 - val_loss: 0.3319\n",
      "Epoch 141/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3415\n",
      "Epoch 141: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3379 - val_loss: 0.3520\n",
      "Epoch 142/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3355\n",
      "Epoch 142: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3362 - val_loss: 0.3358\n",
      "Epoch 143/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3394\n",
      "Epoch 143: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3399 - val_loss: 0.3438\n",
      "Epoch 144/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3323\n",
      "Epoch 144: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3334 - val_loss: 0.3873\n",
      "Epoch 145/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3362\n",
      "Epoch 145: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3358 - val_loss: 0.3358\n",
      "Epoch 146/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3293\n",
      "Epoch 146: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3302 - val_loss: 0.3502\n",
      "Epoch 147/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3385\n",
      "Epoch 147: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3366 - val_loss: 0.3332\n",
      "Epoch 148/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3343\n",
      "Epoch 148: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3355 - val_loss: 0.3570\n",
      "Epoch 149/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3303\n",
      "Epoch 149: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3327 - val_loss: 0.3393\n",
      "Epoch 150/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3341\n",
      "Epoch 150: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3316 - val_loss: 0.3471\n",
      "Epoch 151/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3339\n",
      "Epoch 151: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3344 - val_loss: 0.3639\n",
      "Epoch 152/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3290\n",
      "Epoch 152: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3305 - val_loss: 0.3410\n",
      "Epoch 153/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3333\n",
      "Epoch 153: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3341 - val_loss: 0.3770\n",
      "Epoch 154/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3331\n",
      "Epoch 154: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3332 - val_loss: 0.3981\n",
      "Epoch 155/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3325\n",
      "Epoch 155: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3357 - val_loss: 0.3526\n",
      "Epoch 156/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3368\n",
      "Epoch 156: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3334 - val_loss: 0.3474\n",
      "Epoch 157/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3308\n",
      "Epoch 157: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3296 - val_loss: 0.3945\n",
      "Epoch 158/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3345\n",
      "Epoch 158: val_loss did not improve from 0.33138\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3342 - val_loss: 0.3440\n",
      "Epoch 159/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3283\n",
      "Epoch 159: val_loss improved from 0.33138 to 0.33005, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3287 - val_loss: 0.3301\n",
      "Epoch 160/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3347\n",
      "Epoch 160: val_loss did not improve from 0.33005\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3340 - val_loss: 0.3570\n",
      "Epoch 161/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3217\n",
      "Epoch 161: val_loss did not improve from 0.33005\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3235 - val_loss: 0.3314\n",
      "Epoch 162/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3346\n",
      "Epoch 162: val_loss did not improve from 0.33005\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3351 - val_loss: 0.3482\n",
      "Epoch 163/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3334\n",
      "Epoch 163: val_loss did not improve from 0.33005\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3356 - val_loss: 0.3860\n",
      "Epoch 164/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3336\n",
      "Epoch 164: val_loss did not improve from 0.33005\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3342 - val_loss: 0.3665\n",
      "Epoch 165/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3307\n",
      "Epoch 165: val_loss improved from 0.33005 to 0.32876, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3302 - val_loss: 0.3288\n",
      "Epoch 166/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3260\n",
      "Epoch 166: val_loss did not improve from 0.32876\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3258 - val_loss: 0.4632\n",
      "Epoch 167/300\n",
      "123/137 [=========================>....] - ETA: 0s - loss: 0.3338\n",
      "Epoch 167: val_loss did not improve from 0.32876\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3364 - val_loss: 0.3294\n",
      "Epoch 168/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3272\n",
      "Epoch 168: val_loss did not improve from 0.32876\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3272 - val_loss: 0.3481\n",
      "Epoch 169/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3290\n",
      "Epoch 169: val_loss did not improve from 0.32876\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3290 - val_loss: 0.3305\n",
      "Epoch 170/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3265\n",
      "Epoch 170: val_loss did not improve from 0.32876\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3260 - val_loss: 0.3290\n",
      "Epoch 171/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3310\n",
      "Epoch 171: val_loss improved from 0.32876 to 0.32787, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3318 - val_loss: 0.3279\n",
      "Epoch 172/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3261\n",
      "Epoch 172: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3273 - val_loss: 0.3337\n",
      "Epoch 173/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3295\n",
      "Epoch 173: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3295 - val_loss: 0.3347\n",
      "Epoch 174/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3269\n",
      "Epoch 174: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3269 - val_loss: 0.3298\n",
      "Epoch 175/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3278\n",
      "Epoch 175: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3279 - val_loss: 0.3324\n",
      "Epoch 176/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3233\n",
      "Epoch 176: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3230 - val_loss: 0.3526\n",
      "Epoch 177/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3233\n",
      "Epoch 177: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3233 - val_loss: 0.3295\n",
      "Epoch 178/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3262\n",
      "Epoch 178: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3284 - val_loss: 0.3352\n",
      "Epoch 179/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3286\n",
      "Epoch 179: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3284 - val_loss: 0.3376\n",
      "Epoch 180/300\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 0.3278\n",
      "Epoch 180: val_loss did not improve from 0.32787\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3257 - val_loss: 0.3468\n",
      "Epoch 181/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3188\n",
      "Epoch 181: val_loss improved from 0.32787 to 0.32731, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3190 - val_loss: 0.3273\n",
      "Epoch 182/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3264\n",
      "Epoch 182: val_loss did not improve from 0.32731\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3273 - val_loss: 0.3723\n",
      "Epoch 183/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3257\n",
      "Epoch 183: val_loss did not improve from 0.32731\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3260 - val_loss: 0.4329\n",
      "Epoch 184/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3216\n",
      "Epoch 184: val_loss did not improve from 0.32731\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3216 - val_loss: 0.4245\n",
      "Epoch 185/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3273\n",
      "Epoch 185: val_loss did not improve from 0.32731\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3275 - val_loss: 0.3328\n",
      "Epoch 186/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3249\n",
      "Epoch 186: val_loss improved from 0.32731 to 0.32676, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3246 - val_loss: 0.3268\n",
      "Epoch 187/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3222\n",
      "Epoch 187: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3217 - val_loss: 0.3764\n",
      "Epoch 188/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3227\n",
      "Epoch 188: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3233 - val_loss: 0.3295\n",
      "Epoch 189/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3212\n",
      "Epoch 189: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3227 - val_loss: 0.4071\n",
      "Epoch 190/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3271\n",
      "Epoch 190: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3262 - val_loss: 0.3414\n",
      "Epoch 191/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3252\n",
      "Epoch 191: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3253 - val_loss: 0.3373\n",
      "Epoch 192/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3238\n",
      "Epoch 192: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3237 - val_loss: 0.3783\n",
      "Epoch 193/300\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 0.3230\n",
      "Epoch 193: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3238 - val_loss: 0.3270\n",
      "Epoch 194/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3207\n",
      "Epoch 194: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3231 - val_loss: 0.4966\n",
      "Epoch 195/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3234\n",
      "Epoch 195: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3234 - val_loss: 0.3293\n",
      "Epoch 196/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3247\n",
      "Epoch 196: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3244 - val_loss: 0.3725\n",
      "Epoch 197/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3221\n",
      "Epoch 197: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3221 - val_loss: 0.3291\n",
      "Epoch 198/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3185\n",
      "Epoch 198: val_loss did not improve from 0.32676\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3197 - val_loss: 0.3417\n",
      "Epoch 199/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3249\n",
      "Epoch 199: val_loss improved from 0.32676 to 0.32520, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3243 - val_loss: 0.3252\n",
      "Epoch 200/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3199\n",
      "Epoch 200: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3197 - val_loss: 0.3439\n",
      "Epoch 201/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3284\n",
      "Epoch 201: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3262 - val_loss: 0.3311\n",
      "Epoch 202/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3163\n",
      "Epoch 202: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3182 - val_loss: 0.3254\n",
      "Epoch 203/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3183\n",
      "Epoch 203: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3170 - val_loss: 0.3538\n",
      "Epoch 204/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3164\n",
      "Epoch 204: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3175 - val_loss: 0.3370\n",
      "Epoch 205/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3138\n",
      "Epoch 205: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3138 - val_loss: 0.3283\n",
      "Epoch 206/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3220\n",
      "Epoch 206: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3220 - val_loss: 0.5478\n",
      "Epoch 207/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3262\n",
      "Epoch 207: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3268 - val_loss: 0.3253\n",
      "Epoch 208/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3278\n",
      "Epoch 208: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3259 - val_loss: 0.3486\n",
      "Epoch 209/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3108\n",
      "Epoch 209: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3116 - val_loss: 0.3966\n",
      "Epoch 210/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3198\n",
      "Epoch 210: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3194 - val_loss: 0.4072\n",
      "Epoch 211/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3203\n",
      "Epoch 211: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3199 - val_loss: 0.3367\n",
      "Epoch 212/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3164\n",
      "Epoch 212: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3167 - val_loss: 0.3887\n",
      "Epoch 213/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3199\n",
      "Epoch 213: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3199 - val_loss: 0.3515\n",
      "Epoch 214/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3129\n",
      "Epoch 214: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3136 - val_loss: 0.3492\n",
      "Epoch 215/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3144\n",
      "Epoch 215: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3132 - val_loss: 0.3349\n",
      "Epoch 216/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3179\n",
      "Epoch 216: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3184 - val_loss: 0.3651\n",
      "Epoch 217/300\n",
      "131/137 [===========================>..] - ETA: 0s - loss: 0.3108\n",
      "Epoch 217: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3150 - val_loss: 0.3288\n",
      "Epoch 218/300\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 0.3166\n",
      "Epoch 218: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3165 - val_loss: 0.3280\n",
      "Epoch 219/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3241\n",
      "Epoch 219: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3231 - val_loss: 0.4354\n",
      "Epoch 220/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3159\n",
      "Epoch 220: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3160 - val_loss: 0.5547\n",
      "Epoch 221/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3198\n",
      "Epoch 221: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3195 - val_loss: 0.3875\n",
      "Epoch 222/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3190\n",
      "Epoch 222: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3184 - val_loss: 0.3346\n",
      "Epoch 223/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3113\n",
      "Epoch 223: val_loss did not improve from 0.32520\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3136 - val_loss: 0.3252\n",
      "Epoch 224/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3145\n",
      "Epoch 224: val_loss improved from 0.32520 to 0.32487, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3136 - val_loss: 0.3249\n",
      "Epoch 225/300\n",
      "130/137 [===========================>..] - ETA: 0s - loss: 0.3085\n",
      "Epoch 225: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3093 - val_loss: 0.3709\n",
      "Epoch 226/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3126\n",
      "Epoch 226: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3148 - val_loss: 0.3315\n",
      "Epoch 227/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3138\n",
      "Epoch 227: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3121 - val_loss: 0.3265\n",
      "Epoch 228/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3105\n",
      "Epoch 228: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3110 - val_loss: 0.3266\n",
      "Epoch 229/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3172\n",
      "Epoch 229: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3164 - val_loss: 0.3320\n",
      "Epoch 230/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3176\n",
      "Epoch 230: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3186 - val_loss: 0.3492\n",
      "Epoch 231/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3158\n",
      "Epoch 231: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3162 - val_loss: 0.3411\n",
      "Epoch 232/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3110\n",
      "Epoch 232: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3118 - val_loss: 0.4148\n",
      "Epoch 233/300\n",
      "129/137 [===========================>..] - ETA: 0s - loss: 0.3165\n",
      "Epoch 233: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3155 - val_loss: 0.3679\n",
      "Epoch 234/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3126\n",
      "Epoch 234: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3119 - val_loss: 0.3576\n",
      "Epoch 235/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3117\n",
      "Epoch 235: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3130 - val_loss: 0.3869\n",
      "Epoch 236/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3118\n",
      "Epoch 236: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3114 - val_loss: 0.3464\n",
      "Epoch 237/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3122\n",
      "Epoch 237: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3130 - val_loss: 0.3722\n",
      "Epoch 238/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3175\n",
      "Epoch 238: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3173 - val_loss: 0.3479\n",
      "Epoch 239/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3165\n",
      "Epoch 239: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3140 - val_loss: 0.3260\n",
      "Epoch 240/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3156\n",
      "Epoch 240: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3158 - val_loss: 0.5205\n",
      "Epoch 241/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3132\n",
      "Epoch 241: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3099 - val_loss: 0.3303\n",
      "Epoch 242/300\n",
      "128/137 [===========================>..] - ETA: 0s - loss: 0.3165\n",
      "Epoch 242: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3168 - val_loss: 0.3542\n",
      "Epoch 243/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3057\n",
      "Epoch 243: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3036 - val_loss: 0.3399\n",
      "Epoch 244/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3112\n",
      "Epoch 244: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3113 - val_loss: 0.3255\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - ETA: 0s - loss: 0.3137\n",
      "Epoch 245: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3137 - val_loss: 0.3450\n",
      "Epoch 246/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3192\n",
      "Epoch 246: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3180 - val_loss: 0.3797\n",
      "Epoch 247/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3099\n",
      "Epoch 247: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3097 - val_loss: 0.3301\n",
      "Epoch 248/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3024\n",
      "Epoch 248: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3032 - val_loss: 0.4273\n",
      "Epoch 249/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3091\n",
      "Epoch 249: val_loss did not improve from 0.32487\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3091 - val_loss: 0.3272\n",
      "Epoch 250/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3102\n",
      "Epoch 250: val_loss improved from 0.32487 to 0.32383, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.3102 - val_loss: 0.3238\n",
      "Epoch 251/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3081\n",
      "Epoch 251: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3082 - val_loss: 0.3705\n",
      "Epoch 252/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3053\n",
      "Epoch 252: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3058 - val_loss: 0.4987\n",
      "Epoch 253/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3104\n",
      "Epoch 253: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3128 - val_loss: 0.3244\n",
      "Epoch 254/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3117\n",
      "Epoch 254: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3103 - val_loss: 0.3275\n",
      "Epoch 255/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3033\n",
      "Epoch 255: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3050 - val_loss: 0.3857\n",
      "Epoch 256/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.3073\n",
      "Epoch 256: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3127 - val_loss: 0.3312\n",
      "Epoch 257/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3116\n",
      "Epoch 257: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3116 - val_loss: 0.3398\n",
      "Epoch 258/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3009\n",
      "Epoch 258: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3004 - val_loss: 0.3259\n",
      "Epoch 259/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3121\n",
      "Epoch 259: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3117 - val_loss: 0.3710\n",
      "Epoch 260/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3009\n",
      "Epoch 260: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3009 - val_loss: 0.3253\n",
      "Epoch 261/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3060\n",
      "Epoch 261: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3052 - val_loss: 0.3300\n",
      "Epoch 262/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.3116\n",
      "Epoch 262: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3108 - val_loss: 0.3272\n",
      "Epoch 263/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3002\n",
      "Epoch 263: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3005 - val_loss: 0.3411\n",
      "Epoch 264/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3096\n",
      "Epoch 264: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3087 - val_loss: 0.3794\n",
      "Epoch 265/300\n",
      "132/137 [===========================>..] - ETA: 0s - loss: 0.3055\n",
      "Epoch 265: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3045 - val_loss: 0.3566\n",
      "Epoch 266/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.2952\n",
      "Epoch 266: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2955 - val_loss: 0.3251\n",
      "Epoch 267/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3085\n",
      "Epoch 267: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3069 - val_loss: 0.3587\n",
      "Epoch 268/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3065\n",
      "Epoch 268: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3080 - val_loss: 0.4198\n",
      "Epoch 269/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.2954\n",
      "Epoch 269: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2954 - val_loss: 0.3394\n",
      "Epoch 270/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.2947\n",
      "Epoch 270: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2949 - val_loss: 0.3642\n",
      "Epoch 271/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3163\n",
      "Epoch 271: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3158 - val_loss: 0.3545\n",
      "Epoch 272/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3003\n",
      "Epoch 272: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3002 - val_loss: 0.3242\n",
      "Epoch 273/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3049\n",
      "Epoch 273: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3065 - val_loss: 0.3769\n",
      "Epoch 274/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3055\n",
      "Epoch 274: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3076 - val_loss: 0.3983\n",
      "Epoch 275/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3028\n",
      "Epoch 275: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3067 - val_loss: 0.3302\n",
      "Epoch 276/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2971\n",
      "Epoch 276: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2971 - val_loss: 0.3293\n",
      "Epoch 277/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.3101\n",
      "Epoch 277: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3108 - val_loss: 0.3550\n",
      "Epoch 278/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2930\n",
      "Epoch 278: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2930 - val_loss: 0.3379\n",
      "Epoch 279/300\n",
      "134/137 [============================>.] - ETA: 0s - loss: 0.2957\n",
      "Epoch 279: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2946 - val_loss: 0.3365\n",
      "Epoch 280/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3000\n",
      "Epoch 280: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3001 - val_loss: 0.3399\n",
      "Epoch 281/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3022\n",
      "Epoch 281: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3016 - val_loss: 0.3822\n",
      "Epoch 282/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - ETA: 0s - loss: 0.3028\n",
      "Epoch 282: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3028 - val_loss: 0.3632\n",
      "Epoch 283/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.3030\n",
      "Epoch 283: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3043 - val_loss: 0.3929\n",
      "Epoch 284/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3016\n",
      "Epoch 284: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3016 - val_loss: 0.4428\n",
      "Epoch 285/300\n",
      "135/137 [============================>.] - ETA: 0s - loss: 0.2941\n",
      "Epoch 285: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2941 - val_loss: 0.3523\n",
      "Epoch 286/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.2933\n",
      "Epoch 286: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2920 - val_loss: 0.3282\n",
      "Epoch 287/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3011\n",
      "Epoch 287: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3013 - val_loss: 0.3278\n",
      "Epoch 288/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3036\n",
      "Epoch 288: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3030 - val_loss: 0.3420\n",
      "Epoch 289/300\n",
      "133/137 [============================>.] - ETA: 0s - loss: 0.3015\n",
      "Epoch 289: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2997 - val_loss: 0.3342\n",
      "Epoch 290/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.3057\n",
      "Epoch 290: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3060 - val_loss: 0.3378\n",
      "Epoch 291/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.3066\n",
      "Epoch 291: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.3051 - val_loss: 0.3260\n",
      "Epoch 292/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.2998\n",
      "Epoch 292: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2998 - val_loss: 0.3626\n",
      "Epoch 293/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.2898\n",
      "Epoch 293: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2924 - val_loss: 0.3449\n",
      "Epoch 294/300\n",
      "127/137 [==========================>...] - ETA: 0s - loss: 0.2967\n",
      "Epoch 294: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2994 - val_loss: 0.3308\n",
      "Epoch 295/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.2903\n",
      "Epoch 295: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2920 - val_loss: 0.4169\n",
      "Epoch 296/300\n",
      "124/137 [==========================>...] - ETA: 0s - loss: 0.2989\n",
      "Epoch 296: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2991 - val_loss: 0.3289\n",
      "Epoch 297/300\n",
      "125/137 [==========================>...] - ETA: 0s - loss: 0.2980\n",
      "Epoch 297: val_loss did not improve from 0.32383\n",
      "137/137 [==============================] - 1s 5ms/step - loss: 0.2995 - val_loss: 0.3432\n",
      "Epoch 298/300\n",
      "126/137 [==========================>...] - ETA: 0s - loss: 0.2912\n",
      "Epoch 298: val_loss improved from 0.32383 to 0.32190, saving model to ./models\\checkpoint\n",
      "INFO:tensorflow:Assets written to: ./models\\checkpoint\\assets\n",
      "137/137 [==============================] - 1s 10ms/step - loss: 0.2935 - val_loss: 0.3219\n",
      "Epoch 299/300\n",
      "136/137 [============================>.] - ETA: 0s - loss: 0.3026\n",
      "Epoch 299: val_loss did not improve from 0.32190\n",
      "137/137 [==============================] - 1s 6ms/step - loss: 0.3027 - val_loss: 0.3324\n",
      "Epoch 300/300\n",
      "137/137 [==============================] - ETA: 0s - loss: 0.3050\n",
      "Epoch 300: val_loss did not improve from 0.32190\n",
      "137/137 [==============================] - 1s 4ms/step - loss: 0.3050 - val_loss: 0.3289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15803edf8e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=SGD(momentum=0.02), loss=CategoricalCrossentropy())\n",
    "\n",
    "model.fit(x=train_x,\n",
    "         y=train_y,\n",
    "         batch_size=128,\n",
    "         epochs=300,\n",
    "         validation_split=0.3,\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c315d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_value(row):\n",
    "    if (row == 0):\n",
    "        return '+'\n",
    "    elif (row == 1) :\n",
    "        return '-'\n",
    "\n",
    "def remap(y):\n",
    "    res= y.argmax(axis=1)\n",
    "    df = pd.DataFrame(res, columns=['Predicted'])\n",
    "    df['Predicted'] = df['Predicted'].apply(change_value)\n",
    "    return df\n",
    "\n",
    "def predict_result(model, x):    \n",
    "    y_pred = model.predict(x)\n",
    "    return remap(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72707a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_result(model, train_x)\n",
    "y_true = remap(train_y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6c823be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.88224\n",
      "f1: 0.88224\n"
     ]
    }
   ],
   "source": [
    "print(f\"acc: {accuracy_score(y_pred,y_true)}\")\n",
    "print(f\"f1: {f1_score(y_pred,y_true, average='micro')}\")              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7385cbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x15811d46130>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46c26ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
