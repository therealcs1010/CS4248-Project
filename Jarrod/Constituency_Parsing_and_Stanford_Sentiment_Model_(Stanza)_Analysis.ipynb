{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Constituency Parsing and Stanford Sentiment Model (Stanza) Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a11e17d8c8fe400fbf20aae0b3bdf643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5150489ad20b46cf9fd1b7affaa6a536",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b91ebc9d80614573bcf8053d41c65845",
              "IPY_MODEL_383ad1bee1f245c5877cbd8c3467e64c",
              "IPY_MODEL_c35b100f26af4bdb9c629564cca14e32"
            ]
          }
        },
        "5150489ad20b46cf9fd1b7affaa6a536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b91ebc9d80614573bcf8053d41c65845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97a8c8f9789b4168a0ba50a4566a67e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f60de9f58344fe1b425cc694c5ce2b3"
          }
        },
        "383ad1bee1f245c5877cbd8c3467e64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ef4bf35d34248cfb1f72fc57d2d57d6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 24459,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24459,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_929034920b734afbbf0c5ba434eedf0f"
          }
        },
        "c35b100f26af4bdb9c629564cca14e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b6391c8a63741c6a13e0a2952e94fc4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 142k/? [00:00&lt;00:00, 2.82MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eedde6c64a194af4b1dd0525af57f4ec"
          }
        },
        "97a8c8f9789b4168a0ba50a4566a67e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f60de9f58344fe1b425cc694c5ce2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ef4bf35d34248cfb1f72fc57d2d57d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "929034920b734afbbf0c5ba434eedf0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b6391c8a63741c6a13e0a2952e94fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eedde6c64a194af4b1dd0525af57f4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90c3879ecbbd4ee3b9b073b4e62e4218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4afe675c273941489fca6ad377645623",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d58186d2129f43b38045cf29ef850ed7",
              "IPY_MODEL_17564a2784b149c4b15462331448c84a",
              "IPY_MODEL_badbb8c68cef4b0a8861b683b6e790fb"
            ]
          }
        },
        "4afe675c273941489fca6ad377645623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d58186d2129f43b38045cf29ef850ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6534a82484d64b3285f22462ddae54d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.3.0/models/default.zip: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7b47896cadbf4dc9a63f9d3a0061ad3c"
          }
        },
        "17564a2784b149c4b15462331448c84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7ebb69d28364cbf801fc407b174ff72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 479531529,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 479531529,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bd90382f7444a69bd78af31f83759ac"
          }
        },
        "badbb8c68cef4b0a8861b683b6e790fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2711a64b4a4a4d6d8ede7704e18808a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 480M/480M [00:04&lt;00:00, 124MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3cdf0b043ab14b86b1a28b764059da21"
          }
        },
        "6534a82484d64b3285f22462ddae54d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7b47896cadbf4dc9a63f9d3a0061ad3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7ebb69d28364cbf801fc407b174ff72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bd90382f7444a69bd78af31f83759ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2711a64b4a4a4d6d8ede7704e18808a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3cdf0b043ab14b86b1a28b764059da21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For Google Colaboratory\n",
        "import sys, os\n",
        "if 'google.colab' in sys.modules:\n",
        "    # mount google drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive', force_remount=True)\n",
        "    path_to_file = '/content/gdrive/My Drive/Github/CS4248-Project/Jarrod/'\n",
        "    print(path_to_file)\n",
        "    # move to Google Drive directory\n",
        "    os.chdir(path_to_file)\n",
        "    !pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03PXNLLkAFHt",
        "outputId": "543d08da-5b0c-46c1-c1fb-ac51692d8270"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Github/CS4248-Project/Jarrod/\n",
            "/content/gdrive/My Drive/Github/CS4248-Project/Jarrod\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanfordcorenlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asT8mghxA10k",
        "outputId": "7b21d533-8b39-4b7c-ada2-b103e75fe117"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanfordcorenlp\n",
            "  Downloading stanfordcorenlp-3.9.1.1-py2.py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp) (2.23.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from stanfordcorenlp) (5.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanfordcorenlp) (3.0.4)\n",
            "Installing collected packages: stanfordcorenlp\n",
            "Successfully installed stanfordcorenlp-3.9.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kwZJ3bKycR-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f802b1-c7a9-40fc-c708-e1d6abe82dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constituency Parsing: (ROOT\n",
            "  (S\n",
            "    (NP (PRP$ My) (NN dog))\n",
            "    (VP (VBZ likes)\n",
            "      (S\n",
            "        (VP (TO to)\n",
            "          (VP (VB shake)\n",
            "            (NP (PRP$ his) (VBN stuffed) (NN chikadee) (NN toy))))))\n",
            "    (. .)))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from stanfordcorenlp import StanfordCoreNLP\n",
        "\n",
        "nlp = StanfordCoreNLP(r'stanford-corenlp-4.4.0')\n",
        "\n",
        "sentence = 'My dog likes to shake his stuffed chikadee toy. Hey there how are you doing!'\n",
        "print ('Constituency Parsing:', nlp.parse(sentence))\n",
        "\n",
        "nlp.close() # Do not forget to close! The backend server will consume a lot memery."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "neg_data = open(\"all_neg.txt\", \"r\")\n",
        "neg_lines = neg_data.readlines()\n",
        "print (len(neg_lines))\n",
        "neg_data.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvZbplbwRVFz",
        "outputId": "ecf1abbd-8e3f-43e7-ffa2-03eff3718e59"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_data = open(\"all_pos.txt\", \"r\")\n",
        "pos_lines = pos_data.readlines()\n",
        "print (len(pos_lines))\n",
        "pos_data.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CseHRuyJTobi",
        "outputId": "f8fe9a60-1c9f-4852-872d-e32f7072fb80"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_neg_data = open(\"test_neg.txt\", \"r\")\n",
        "test_neg_lines = test_neg_data.readlines()\n",
        "print (len(test_neg_lines))\n",
        "test_neg_data.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2utfjr8f1fYW",
        "outputId": "893a811a-10d7-4c3d-9e2c-72e444f047cc"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pos_data = open(\"test_pos.txt\", \"r\")\n",
        "test_pos_lines = test_pos_data.readlines()\n",
        "print (len(test_pos_lines))\n",
        "test_pos_data.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cfzlYaL1fm9",
        "outputId": "e6866508-f9a6-4a2b-c636-c51063f26abe"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pos_lines[0])\n",
        "print(neg_lines[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj-UyFYuTwr_",
        "outputId": "958b0ab6-f87f-47b8-a0ea-8bc220b2678d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.\n",
            "\n",
            "Working with one of the best Shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.<br /><br />Branagh steals the film from under Fishburne's nose, and there's a talented cast on good form.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we need to clean up the data to remove any line breaks etc.\n",
        "\n",
        "Remove any websites and emails also.\n",
        "\n",
        "regex for Urls taken from : https://stackoverflow.com/questions/3809401/what-is-a-good-regular-expression-to-match-a-url\n"
      ],
      "metadata": {
        "id": "E2S0GV1cUCPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "neg_lines_replaced = [re.sub(\"<br />|(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\",\" \",line) for line in neg_lines]\n",
        "pos_lines_replaced = [re.sub(\"<br />|(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\",\" \",line) for line in pos_lines]\n",
        "test_neg_replaced = [re.sub(\"<br />|(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\",\" \",line) for line in test_neg_lines]\n",
        "test_pos_replaced = [re.sub(\"<br />|(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\",\" \",line) for line in test_pos_lines]"
      ],
      "metadata": {
        "id": "59FXVDhhTwz6"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After cleaning, we want to create the trees that will help to store the data for treeLSTM/recursive NNs\n",
        "\n",
        "For each review, note that we will assign the sentiment value to each sentence based on the overall sentiment of the review by its label. If its negative, then each sentence will be -1; +1 for positive.\n",
        "\n",
        "There are other ways to tackle this also in the process to build a tree and parse the data. For example, rather than have each sentence in the review be -1/1, it could be an average. If the review has 4 sentences and it reads as negative, then we know that each sentence will represent 1/4 of the overall movie sentiment. This is something else that can be tried with."
      ],
      "metadata": {
        "id": "CxKeCXbSU5ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(neg_lines_replaced[0])\n",
        "print(type(neg_lines_replaced[0]))\n",
        "\n",
        "def text_to_sentences(lines):\n",
        "  result = []\n",
        "  for line in lines:\n",
        "    sents = nltk.tokenize.sent_tokenize(line)\n",
        "    result = result + sents\n",
        "  return result\n",
        "\n",
        "neg_lines_sentences = text_to_sentences(neg_lines_replaced)\n",
        "print(neg_lines_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbYLn9tKVION",
        "outputId": "89902c30-08f4-43b0-9411-a26007002b42"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Working with one of the best Shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.  Branagh steals the film from under Fishburne's nose, and there's a talented cast on good form.\n",
            "\n",
            "<class 'str'>\n",
            "Working with one of the best Shakespeare sources, this film manages to be creditable to it's source, whilst still appealing to a wider audience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_lines_sentences = text_to_sentences(pos_lines_replaced)\n",
        "print(len(pos_lines_sentences))\n",
        "print(len(neg_lines_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFJwDuUQc5Ve",
        "outputId": "157b0ff1-7966-4cc2-fcb1-38d0a1a1752d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151999\n",
            "159297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_neg_lines_sentences = text_to_sentences(test_neg_replaced)\n",
        "test_pos_lines_sentences = text_to_sentences(test_pos_replaced)\n",
        "print(len(test_pos_lines_sentences))\n",
        "print(len(test_neg_lines_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpWEFi8z2KkU",
        "outputId": "225899b5-3c3e-4db3-a80d-9cd131bea82d"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148144\n",
            "156816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next part is a sample tree structure of the sentences in the sentences array to be passed into the TreeLSTM / Recursive NN for learning."
      ],
      "metadata": {
        "id": "0KUIibRmdzUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = StanfordCoreNLP(r'stanford-corenlp-4.4.0')\n",
        "\n",
        "print(nlp.parse(neg_lines_sentences[0]))\n",
        "\n",
        "nlp.close()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLWNHPyhdTVM",
        "outputId": "f6585bb1-ae07-41c9-8ee8-7bb2eab17661"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(ROOT\n",
            "  (S\n",
            "    (S\n",
            "      (VP (VBG Working)\n",
            "        (PP (IN with)\n",
            "          (NP\n",
            "            (NP (CD one))\n",
            "            (PP (IN of)\n",
            "              (NP (DT the) (JJS best) (NNP Shakespeare) (NNS sources)))))))\n",
            "    (, ,)\n",
            "    (NP (DT this) (NN film))\n",
            "    (VP (VBZ manages)\n",
            "      (S\n",
            "        (VP (TO to)\n",
            "          (VP (VB be)\n",
            "            (ADJP (JJ creditable))\n",
            "            (SBAR (IN to)\n",
            "              (S\n",
            "                (NP (PRP it))\n",
            "                (VP (VBZ 's)\n",
            "                  (NP (NN source)))))\n",
            "            (, ,)\n",
            "            (PP (IN whilst)\n",
            "              (S\n",
            "                (ADVP (RB still))\n",
            "                (VP (VBG appealing)\n",
            "                  (PP (IN to)\n",
            "                    (NP (DT a) (JJR wider) (NN audience))))))))))\n",
            "    (. .)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stanza"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QCzr9tRes-U",
        "outputId": "720610da-39ad-4944-f405-323d409470ba"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 307 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 358 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 368 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 419 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 430 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 432 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.6.3.tar.gz (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.3-py3-none-any.whl size=170298 sha256=43878448d9e65d7f9af66dcb52b40a0a066569a28fda77f450924d80d2bd5241\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/8b/d7/ad579fbef83c287215c0caab60fb0ae0f30c4d7ce5f580eade\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, stanza\n",
            "Successfully installed emoji-1.6.3 stanza-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can used the model developed by Stanford team to check what would the the outcome of the individual sentences in our movie review sentiment, and then we would develop a specific matrix to determine the overall efficacy of the stanford sentiment model."
      ],
      "metadata": {
        "id": "PC9-L8DKmsDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza\n",
        "stanza.install_corenlp()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee3Loy7tewss",
        "outputId": "e3014ad1-f0e3-47be-fd8a-587acb5e7987"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:stanza:Directory /root/stanza_corenlp already exists. Please install CoreNLP to a new directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download('en')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "a11e17d8c8fe400fbf20aae0b3bdf643",
            "5150489ad20b46cf9fd1b7affaa6a536",
            "b91ebc9d80614573bcf8053d41c65845",
            "383ad1bee1f245c5877cbd8c3467e64c",
            "c35b100f26af4bdb9c629564cca14e32",
            "97a8c8f9789b4168a0ba50a4566a67e3",
            "5f60de9f58344fe1b425cc694c5ce2b3",
            "9ef4bf35d34248cfb1f72fc57d2d57d6",
            "929034920b734afbbf0c5ba434eedf0f",
            "8b6391c8a63741c6a13e0a2952e94fc4",
            "eedde6c64a194af4b1dd0525af57f4ec",
            "90c3879ecbbd4ee3b9b073b4e62e4218",
            "4afe675c273941489fca6ad377645623",
            "d58186d2129f43b38045cf29ef850ed7",
            "17564a2784b149c4b15462331448c84a",
            "badbb8c68cef4b0a8861b683b6e790fb",
            "6534a82484d64b3285f22462ddae54d9",
            "7b47896cadbf4dc9a63f9d3a0061ad3c",
            "e7ebb69d28364cbf801fc407b174ff72",
            "9bd90382f7444a69bd78af31f83759ac",
            "2711a64b4a4a4d6d8ede7704e18808a1",
            "3cdf0b043ab14b86b1a28b764059da21"
          ]
        },
        "id": "XW8YTU4OtvCj",
        "outputId": "0fd474d1-4a9f-454d-f572-6318979a12ec"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a11e17d8c8fe400fbf20aae0b3bdf643",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloading default packages for language: en (English)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90c3879ecbbd4ee3b9b073b4e62e4218",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.3.0/models/default.zip:   0%|          | 0…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the stanza module to do our own constituency parsing that can be passed into a TreeLSTM model for training. Here, I am only using a benchmark of 100 sentences in the entire sentence corpus to understand the resource-constraints of preparing data for a TreeLSTM model. Note that with simple cleaning of the data the negative_sentences corpus alone already has a size of >150000 sentences."
      ],
      "metadata": {
        "id": "jmR59HS8s13w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stanza.server import CoreNLPClient\n",
        "\n",
        "\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
        "\n",
        "import time\n",
        "\n",
        "neg_constituents_map = []\n",
        "i = 0\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for sentence in neg_lines_sentences[:100]:\n",
        "  doc = nlp(sentence)\n",
        "  for sentence in doc.sentences:\n",
        "    neg_constituents_map.append(sentence.constituency)\n",
        "\n",
        "end = time.time()\n",
        "print(end - start , ' seconds')\n",
        "print(neg_constituents_map[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWjPEXrpfuBu",
        "outputId": "148460e2-46ac-472d-da83-c7c33e5e595b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Loading these models for language: en (English):\n",
            "===========================\n",
            "| Processor    | Package  |\n",
            "---------------------------\n",
            "| tokenize     | combined |\n",
            "| pos          | combined |\n",
            "| constituency | wsj      |\n",
            "===========================\n",
            "\n",
            "INFO:stanza:Use device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: constituency\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20.252846002578735  seconds\n",
            "(ROOT (S (S (VP (VBG Working) (PP (IN with) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (JJS best) (NNP Shakespeare) (NNS sources))))))) (, ,) (NP (DT this) (NN film)) (VP (VBZ manages) (S (VP (TO to) (VP (VB be) (ADJP (JJ creditable) (PP (IN to) (NP (NP (PRP it) (POS 's)) (NN source)))) (, ,) (PP (IN whilst) (S (ADVP (RB still)) (ADJP (JJ appealing) (PP (IN to) (NP (DT a) (JJR wider) (NN audience)))))))))) (. .)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here what we want to do is to pass our data through the model and evaluate the results. Before passing thru the model, we will first develop a sentence array for each of the individual reviews."
      ],
      "metadata": {
        "id": "JOpLemI42qBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_sentences_arr(lines):\n",
        "  result = []\n",
        "  for line in lines:\n",
        "    sents = nltk.tokenize.sent_tokenize(line)\n",
        "    result.append(sents)\n",
        "  return result\n",
        "\n",
        "\n",
        "test_neg_2d = text_to_sentences_arr(test_neg_replaced)\n",
        "test_pos_2d = text_to_sentences_arr(test_pos_replaced)\n",
        "\n",
        "print(test_neg_2d[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx6L2_8A4AbJ",
        "outputId": "d92e1353-e1db-46d7-966f-35b857b6a2d0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Alan Rickman & Emma Thompson give good performances with southern/New Orleans accents in this detective flick.', \"It's worth seeing for their scenes- and Rickman's scene with Hal Holbrook.\", 'These three actors mannage to entertain us no matter what the movie, it seems.', 'The plot for the movie shows potential, but one gets the impression in watching the film that it was not pulled off as well as it could have been.', 'The fact that it is cluttered by a rather uninteresting subplot and mostly uninteresting kidnappers really muddles things.', 'The movie is worth a view- if for nothing more than entertaining performances by Rickman, Thompson, and Holbrook.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')\n",
        "\n",
        "import time\n",
        "\n",
        "neg_test_sentiments_map = []\n",
        "i=0\n",
        "start = time.time()\n",
        "\n",
        "for review in test_neg_2d[:100]:\n",
        "  doc = nlp(' '.join(review))\n",
        "  review_sentiment_arr = []\n",
        "  for sentence in doc.sentences:\n",
        "    review_sentiment_arr.append(sentence.sentiment)\n",
        "  neg_test_sentiments_map.append(review_sentiment_arr)\n",
        "  print(i)\n",
        "  i=i+1\n",
        "end = time.time()\n",
        "print(end - start , ' seconds')\n",
        "print(neg_test_sentiments_map[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cFfjwPp0n8X",
        "outputId": "7a0ae30b-992d-41bb-cfb9-22c21efa7145"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Loading these models for language: en (English):\n",
            "========================\n",
            "| Processor | Package  |\n",
            "------------------------\n",
            "| tokenize  | combined |\n",
            "| sentiment | sstplus  |\n",
            "========================\n",
            "\n",
            "INFO:stanza:Use device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: sentiment\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "42.43351197242737  seconds\n",
            "[2, 1, 1, 0, 0, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After obtaining the results of the model, we need to make sense of the results. As a result of doing sentence sentiment analysis, we need to identify a good heuristic for us to obtain the overall sentiment of the review. Are we able to then use a regular neural network to do this checking on what might be the best formula?\n",
        "\n",
        "Possible formulas to use include\n",
        "\n",
        "1. Direct summation and averaging\n",
        "2. Number of words in the sentence - requires more data augmentation.\n",
        "3. Removal of stop words?\n",
        "\n",
        "heuristics to include\n",
        "1. threshold for which u identify a sentiment as positive or negative\n",
        "\n",
        "For simplicity, we shall consider the first case first, that is we will use the direct sum of all the values in the array and then divide over to get an average score of the review. If the score is < 0 then the review is negative in sentiment and vice versa."
      ],
      "metadata": {
        "id": "sAsp90iT8XG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0\n",
        "def change_sentiment_value(i):\n",
        "  if i == 2:\n",
        "    return 1\n",
        "  elif i == 0:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def get_sentiments(review):\n",
        "  average_sentiment = sum([change_sentiment_value(i) for i in review])/len(review)\n",
        "  if average_sentiment > threshold:\n",
        "    return 1\n",
        "  elif average_sentiment < threshold:\n",
        "    return -1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "neg_sentiment_results = [get_sentiments(review) for review in neg_test_sentiments_map]\n",
        "print(neg_sentiment_results[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_ymWDM0eIR2",
        "outputId": "af3cfea5-7a89-4900-fbc8-f8c6a5a64e8e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is easy to evaluate the accuracy of the model by looking at the number of values that are not the intended values for the test set.\n",
        "\n",
        "Take for example if we look at the the neg_sentiment_results, which stores the result of each review after running through the Stanford model and producing the result.\n",
        "\n",
        "We simply count the number N of non-(-1)s in the array and then use the formula of [1-(N/len(array))] * 100% to get the eventual accuracy of the model."
      ],
      "metadata": {
        "id": "59l64sw-BgFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_model_accuracy = (neg_sentiment_results.count(-1)/len(neg_sentiment_results))*100\n",
        "print(neg_sentiment_results.count(-1))\n",
        "print(len(neg_sentiment_results))\n",
        "print(neg_model_accuracy)\n",
        "print(neg_sentiment_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTmEx55ACtGT",
        "outputId": "aa19c05d-78d7-4264-97b3-0fff8e51b14f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n",
            "100\n",
            "90.0\n",
            "[0, -1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0, -1, -1, 1, -1, -1, -1, -1, 0, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
          ]
        }
      ]
    }
  ]
}